{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score, make_scorer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred) :\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    \n",
    "    y_true = y_true.reshape(1, -1)[0]\n",
    "    y_pred = y_pred.reshape(1, -1)[0]\n",
    "    over_threshold = y_true >= 0.1\n",
    "    \n",
    "    return np.mean(np.abs(y_true[over_threshold] - y_pred[over_threshold]))\n",
    "\n",
    "def fscore(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    \n",
    "    y_true = y_true.reshape(1, -1)[0]\n",
    "    y_pred = y_pred.reshape(1, -1)[0]\n",
    "    remove_NAs = y_true >= 0\n",
    "    \n",
    "    y_true = np.where(y_true[remove_NAs] >= 0.1, 1, 0)\n",
    "    y_pred = np.where(y_pred[remove_NAs] >= 0.1, 1, 0)\n",
    "    \n",
    "    return (f1_score(y_true, y_pred))\n",
    "\n",
    "def maeOverFscore(y_true, y_pred):\n",
    "    return mae(y_true, y_pred) / (fscore(y_true, y_pred) + 1e-07)\n",
    "\n",
    "def score(y_val, pred):\n",
    "    print(f\"fscore        : {fscore(y_val, pred)}\")\n",
    "    print(f\"maeOverFscore : {maeOverFscore(y_val, pred)}\")\n",
    "\n",
    "fscore_sklearn = make_scorer(fscore)\n",
    "maeOverFscore_sklearn = make_scorer(maeOverFscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = os.getcwd()\n",
    "data_path = os.path.join(base, 'data')\n",
    "submit_path = os.path.join(base, 'submit')\n",
    "model_path = os.path.join(base, 'model')\n",
    "\n",
    "def load_data(name):\n",
    "    return np.load(os.path.join(data_path, f\"{name}.npy\"))\n",
    "\n",
    "def reshape(data):\n",
    "    return data.reshape(data.shape[0] * 40 * 40, data.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = reshape(load_data('dl_train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select K\n",
    "![img](feacture_selection.PNG)\n",
    "\n",
    "### selectK 7\n",
    "- [False, False,  True,  True,  True,  True,  True,  True, False, False, False, False, False, True]\n",
    "\n",
    "### selectK 8\n",
    "- [False, False,  True,  True,  True,  True,  True,  True, False, False, False, True, False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectK_7 = [2, 3, 4, 5, 6, 7, 13]\n",
    "selectK_8 = [2, 3, 4, 5, 6, 7, 11, 13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seperate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121561600, 14) (121561600, 1)\n"
     ]
    }
   ],
   "source": [
    "X = data[:, :-1]\n",
    "Y = data[:,  -1].reshape(data.shape[0], 1)\n",
    "data = range(data.shape[0])\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'learning_rate': 0.01, 'max_depth': -1, 'boosting': 'gbdt', \n",
    "#           'objective': 'regression', 'metric': 'mae', 'is_training_metric': True, \n",
    "#           'num_leaves': 1024, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, \n",
    "#           'bagging_freq': 5, 'seed':7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 3.62028\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's l2: 3.60018\n",
      "[3]\tvalid_0's l2: 3.58033\n",
      "[4]\tvalid_0's l2: 3.56099\n",
      "[5]\tvalid_0's l2: 3.542\n",
      "[6]\tvalid_0's l2: 3.5233\n",
      "[7]\tvalid_0's l2: 3.5051\n",
      "[8]\tvalid_0's l2: 3.48715\n",
      "[9]\tvalid_0's l2: 3.46952\n",
      "[10]\tvalid_0's l2: 3.45236\n",
      "[11]\tvalid_0's l2: 3.43541\n",
      "[12]\tvalid_0's l2: 3.4189\n",
      "[13]\tvalid_0's l2: 3.40261\n",
      "[14]\tvalid_0's l2: 3.38668\n",
      "[15]\tvalid_0's l2: 3.37103\n",
      "[16]\tvalid_0's l2: 3.35575\n",
      "[17]\tvalid_0's l2: 3.34067\n",
      "[18]\tvalid_0's l2: 3.32604\n",
      "[19]\tvalid_0's l2: 3.31158\n",
      "[20]\tvalid_0's l2: 3.29743\n",
      "[21]\tvalid_0's l2: 3.28358\n",
      "[22]\tvalid_0's l2: 3.26995\n",
      "[23]\tvalid_0's l2: 3.25666\n",
      "[24]\tvalid_0's l2: 3.24359\n",
      "[25]\tvalid_0's l2: 3.23071\n",
      "[26]\tvalid_0's l2: 3.21809\n",
      "[27]\tvalid_0's l2: 3.2057\n",
      "[28]\tvalid_0's l2: 3.19361\n",
      "[29]\tvalid_0's l2: 3.18177\n",
      "[30]\tvalid_0's l2: 3.17012\n",
      "[31]\tvalid_0's l2: 3.15866\n",
      "[32]\tvalid_0's l2: 3.14752\n",
      "[33]\tvalid_0's l2: 3.13645\n",
      "[34]\tvalid_0's l2: 3.12561\n",
      "[35]\tvalid_0's l2: 3.1151\n",
      "[36]\tvalid_0's l2: 3.10467\n",
      "[37]\tvalid_0's l2: 3.09445\n",
      "[38]\tvalid_0's l2: 3.08443\n",
      "[39]\tvalid_0's l2: 3.07461\n",
      "[40]\tvalid_0's l2: 3.06509\n",
      "[41]\tvalid_0's l2: 3.05562\n",
      "[42]\tvalid_0's l2: 3.04642\n",
      "[43]\tvalid_0's l2: 3.03731\n",
      "[44]\tvalid_0's l2: 3.02835\n",
      "[45]\tvalid_0's l2: 3.0197\n",
      "[46]\tvalid_0's l2: 3.01107\n",
      "[47]\tvalid_0's l2: 3.00265\n",
      "[48]\tvalid_0's l2: 2.99437\n",
      "[49]\tvalid_0's l2: 2.98633\n",
      "[50]\tvalid_0's l2: 2.97832\n",
      "[51]\tvalid_0's l2: 2.97049\n",
      "[52]\tvalid_0's l2: 2.96284\n",
      "[53]\tvalid_0's l2: 2.95528\n",
      "[54]\tvalid_0's l2: 2.94796\n",
      "[55]\tvalid_0's l2: 2.94081\n",
      "[56]\tvalid_0's l2: 2.93371\n",
      "[57]\tvalid_0's l2: 2.92679\n",
      "[58]\tvalid_0's l2: 2.92\n",
      "[59]\tvalid_0's l2: 2.91337\n",
      "[60]\tvalid_0's l2: 2.9068\n",
      "[61]\tvalid_0's l2: 2.90039\n",
      "[62]\tvalid_0's l2: 2.89409\n",
      "[63]\tvalid_0's l2: 2.88792\n",
      "[64]\tvalid_0's l2: 2.88187\n",
      "[65]\tvalid_0's l2: 2.8759\n",
      "[66]\tvalid_0's l2: 2.87005\n",
      "[67]\tvalid_0's l2: 2.86422\n",
      "[68]\tvalid_0's l2: 2.85862\n",
      "[69]\tvalid_0's l2: 2.85305\n",
      "[70]\tvalid_0's l2: 2.84767\n",
      "[71]\tvalid_0's l2: 2.84232\n",
      "[72]\tvalid_0's l2: 2.83707\n",
      "[73]\tvalid_0's l2: 2.83195\n",
      "[74]\tvalid_0's l2: 2.82697\n",
      "[75]\tvalid_0's l2: 2.82202\n",
      "[76]\tvalid_0's l2: 2.81725\n",
      "[77]\tvalid_0's l2: 2.81247\n",
      "[78]\tvalid_0's l2: 2.80709\n",
      "[79]\tvalid_0's l2: 2.80245\n",
      "[80]\tvalid_0's l2: 2.79793\n",
      "[81]\tvalid_0's l2: 2.79345\n",
      "[82]\tvalid_0's l2: 2.78847\n",
      "[83]\tvalid_0's l2: 2.78421\n",
      "[84]\tvalid_0's l2: 2.77996\n",
      "[85]\tvalid_0's l2: 2.775\n",
      "[86]\tvalid_0's l2: 2.77006\n",
      "[87]\tvalid_0's l2: 2.76604\n",
      "[88]\tvalid_0's l2: 2.76145\n",
      "[89]\tvalid_0's l2: 2.75763\n",
      "[90]\tvalid_0's l2: 2.75287\n",
      "[91]\tvalid_0's l2: 2.74917\n",
      "[92]\tvalid_0's l2: 2.74498\n",
      "[93]\tvalid_0's l2: 2.74142\n",
      "[94]\tvalid_0's l2: 2.73695\n",
      "[95]\tvalid_0's l2: 2.73348\n",
      "[96]\tvalid_0's l2: 2.73017\n",
      "[97]\tvalid_0's l2: 2.72589\n",
      "[98]\tvalid_0's l2: 2.72266\n",
      "[99]\tvalid_0's l2: 2.71946\n",
      "[100]\tvalid_0's l2: 2.71573\n",
      "[101]\tvalid_0's l2: 2.71173\n",
      "[102]\tvalid_0's l2: 2.70871\n",
      "[103]\tvalid_0's l2: 2.70579\n",
      "[104]\tvalid_0's l2: 2.70194\n",
      "[105]\tvalid_0's l2: 2.69908\n",
      "[106]\tvalid_0's l2: 2.69575\n",
      "[107]\tvalid_0's l2: 2.69294\n",
      "[108]\tvalid_0's l2: 2.68935\n",
      "[109]\tvalid_0's l2: 2.68668\n",
      "[110]\tvalid_0's l2: 2.68355\n",
      "[111]\tvalid_0's l2: 2.68099\n",
      "[112]\tvalid_0's l2: 2.67844\n",
      "[113]\tvalid_0's l2: 2.67504\n",
      "[114]\tvalid_0's l2: 2.67256\n",
      "[115]\tvalid_0's l2: 2.66926\n",
      "[116]\tvalid_0's l2: 2.66696\n",
      "[117]\tvalid_0's l2: 2.66467\n",
      "[118]\tvalid_0's l2: 2.66151\n",
      "[119]\tvalid_0's l2: 2.65922\n",
      "[120]\tvalid_0's l2: 2.65702\n",
      "[121]\tvalid_0's l2: 2.65399\n",
      "[122]\tvalid_0's l2: 2.65187\n",
      "[123]\tvalid_0's l2: 2.64884\n",
      "[124]\tvalid_0's l2: 2.64678\n",
      "[125]\tvalid_0's l2: 2.64391\n",
      "[126]\tvalid_0's l2: 2.64194\n",
      "[127]\tvalid_0's l2: 2.64002\n",
      "[128]\tvalid_0's l2: 2.63725\n",
      "[129]\tvalid_0's l2: 2.63531\n",
      "[130]\tvalid_0's l2: 2.63346\n",
      "[131]\tvalid_0's l2: 2.63082\n",
      "[132]\tvalid_0's l2: 2.62897\n",
      "[133]\tvalid_0's l2: 2.62641\n",
      "[134]\tvalid_0's l2: 2.6247\n",
      "[135]\tvalid_0's l2: 2.62261\n",
      "[136]\tvalid_0's l2: 2.62089\n",
      "[137]\tvalid_0's l2: 2.61843\n",
      "[138]\tvalid_0's l2: 2.6168\n",
      "[139]\tvalid_0's l2: 2.61518\n",
      "[140]\tvalid_0's l2: 2.61281\n",
      "[141]\tvalid_0's l2: 2.61128\n",
      "[142]\tvalid_0's l2: 2.60898\n",
      "[143]\tvalid_0's l2: 2.60744\n",
      "[144]\tvalid_0's l2: 2.60556\n",
      "[145]\tvalid_0's l2: 2.60408\n",
      "[146]\tvalid_0's l2: 2.60191\n",
      "[147]\tvalid_0's l2: 2.60042\n",
      "[148]\tvalid_0's l2: 2.59831\n",
      "[149]\tvalid_0's l2: 2.59695\n",
      "[150]\tvalid_0's l2: 2.59563\n",
      "[151]\tvalid_0's l2: 2.59359\n",
      "[152]\tvalid_0's l2: 2.59226\n",
      "[153]\tvalid_0's l2: 2.5906\n",
      "[154]\tvalid_0's l2: 2.58933\n",
      "[155]\tvalid_0's l2: 2.58738\n",
      "[156]\tvalid_0's l2: 2.58611\n",
      "[157]\tvalid_0's l2: 2.58424\n",
      "[158]\tvalid_0's l2: 2.58302\n",
      "[159]\tvalid_0's l2: 2.58152\n",
      "[160]\tvalid_0's l2: 2.58032\n",
      "[161]\tvalid_0's l2: 2.57851\n",
      "[162]\tvalid_0's l2: 2.5774\n",
      "[163]\tvalid_0's l2: 2.57565\n",
      "[164]\tvalid_0's l2: 2.57459\n",
      "[165]\tvalid_0's l2: 2.57286\n",
      "[166]\tvalid_0's l2: 2.57183\n",
      "[167]\tvalid_0's l2: 2.57083\n",
      "[168]\tvalid_0's l2: 2.56921\n",
      "[169]\tvalid_0's l2: 2.56811\n",
      "[170]\tvalid_0's l2: 2.5671\n",
      "[171]\tvalid_0's l2: 2.56545\n",
      "[172]\tvalid_0's l2: 2.56459\n",
      "[173]\tvalid_0's l2: 2.56298\n",
      "[174]\tvalid_0's l2: 2.56211\n",
      "[175]\tvalid_0's l2: 2.56121\n",
      "[176]\tvalid_0's l2: 2.55966\n",
      "[177]\tvalid_0's l2: 2.55882\n",
      "[178]\tvalid_0's l2: 2.55732\n",
      "[179]\tvalid_0's l2: 2.55651\n",
      "[180]\tvalid_0's l2: 2.55567\n",
      "[181]\tvalid_0's l2: 2.55424\n",
      "[182]\tvalid_0's l2: 2.55339\n",
      "[183]\tvalid_0's l2: 2.55199\n",
      "[184]\tvalid_0's l2: 2.55126\n",
      "[185]\tvalid_0's l2: 2.55049\n",
      "[186]\tvalid_0's l2: 2.54913\n",
      "[187]\tvalid_0's l2: 2.54836\n",
      "[188]\tvalid_0's l2: 2.54704\n",
      "[189]\tvalid_0's l2: 2.54635\n",
      "[190]\tvalid_0's l2: 2.54506\n",
      "[191]\tvalid_0's l2: 2.54436\n",
      "[192]\tvalid_0's l2: 2.54359\n",
      "[193]\tvalid_0's l2: 2.54234\n",
      "[194]\tvalid_0's l2: 2.54161\n",
      "[195]\tvalid_0's l2: 2.54044\n",
      "[196]\tvalid_0's l2: 2.53978\n",
      "[197]\tvalid_0's l2: 2.53857\n",
      "[198]\tvalid_0's l2: 2.53801\n",
      "[199]\tvalid_0's l2: 2.53684\n",
      "[200]\tvalid_0's l2: 2.53623\n",
      "[201]\tvalid_0's l2: 2.53511\n",
      "[202]\tvalid_0's l2: 2.53449\n",
      "[203]\tvalid_0's l2: 2.53383\n",
      "[204]\tvalid_0's l2: 2.53273\n",
      "[205]\tvalid_0's l2: 2.53214\n",
      "[206]\tvalid_0's l2: 2.53106\n",
      "[207]\tvalid_0's l2: 2.53054\n",
      "[208]\tvalid_0's l2: 2.52947\n",
      "[209]\tvalid_0's l2: 2.52897\n",
      "[210]\tvalid_0's l2: 2.52795\n",
      "[211]\tvalid_0's l2: 2.52747\n",
      "[212]\tvalid_0's l2: 2.52646\n",
      "[213]\tvalid_0's l2: 2.52597\n",
      "[214]\tvalid_0's l2: 2.52496\n",
      "[215]\tvalid_0's l2: 2.52402\n",
      "[216]\tvalid_0's l2: 2.52342\n",
      "[217]\tvalid_0's l2: 2.52247\n",
      "[218]\tvalid_0's l2: 2.52152\n",
      "[219]\tvalid_0's l2: 2.52058\n",
      "[220]\tvalid_0's l2: 2.51971\n",
      "[221]\tvalid_0's l2: 2.5188\n",
      "[222]\tvalid_0's l2: 2.51793\n",
      "[223]\tvalid_0's l2: 2.51703\n",
      "[224]\tvalid_0's l2: 2.51653\n",
      "[225]\tvalid_0's l2: 2.51567\n",
      "[226]\tvalid_0's l2: 2.51484\n",
      "[227]\tvalid_0's l2: 2.514\n",
      "[228]\tvalid_0's l2: 2.51318\n",
      "[229]\tvalid_0's l2: 2.51265\n",
      "[230]\tvalid_0's l2: 2.51185\n",
      "[231]\tvalid_0's l2: 2.51112\n",
      "[232]\tvalid_0's l2: 2.51041\n",
      "[233]\tvalid_0's l2: 2.50964\n",
      "[234]\tvalid_0's l2: 2.50888\n",
      "[235]\tvalid_0's l2: 2.50842\n",
      "[236]\tvalid_0's l2: 2.5077\n",
      "[237]\tvalid_0's l2: 2.507\n",
      "[238]\tvalid_0's l2: 2.50636\n",
      "[239]\tvalid_0's l2: 2.50563\n",
      "[240]\tvalid_0's l2: 2.50521\n",
      "[241]\tvalid_0's l2: 2.50445\n",
      "[242]\tvalid_0's l2: 2.50384\n",
      "[243]\tvalid_0's l2: 2.5032\n",
      "[244]\tvalid_0's l2: 2.50253\n",
      "[245]\tvalid_0's l2: 2.50196\n",
      "[246]\tvalid_0's l2: 2.50131\n",
      "[247]\tvalid_0's l2: 2.50073\n",
      "[248]\tvalid_0's l2: 2.50014\n",
      "[249]\tvalid_0's l2: 2.49954\n",
      "[250]\tvalid_0's l2: 2.49912\n",
      "[251]\tvalid_0's l2: 2.49849\n",
      "[252]\tvalid_0's l2: 2.49793\n",
      "[253]\tvalid_0's l2: 2.49715\n",
      "[254]\tvalid_0's l2: 2.49662\n",
      "[255]\tvalid_0's l2: 2.4959\n",
      "[256]\tvalid_0's l2: 2.49549\n",
      "[257]\tvalid_0's l2: 2.49478\n",
      "[258]\tvalid_0's l2: 2.49428\n",
      "[259]\tvalid_0's l2: 2.49358\n",
      "[260]\tvalid_0's l2: 2.49293\n",
      "[261]\tvalid_0's l2: 2.49254\n",
      "[262]\tvalid_0's l2: 2.49218\n",
      "[263]\tvalid_0's l2: 2.49155\n",
      "[264]\tvalid_0's l2: 2.49119\n",
      "[265]\tvalid_0's l2: 2.49063\n",
      "[266]\tvalid_0's l2: 2.49029\n",
      "[267]\tvalid_0's l2: 2.4897\n",
      "[268]\tvalid_0's l2: 2.48918\n",
      "[269]\tvalid_0's l2: 2.48911\n",
      "[270]\tvalid_0's l2: 2.48858\n",
      "[271]\tvalid_0's l2: 2.48811\n",
      "[272]\tvalid_0's l2: 2.48804\n",
      "[273]\tvalid_0's l2: 2.48749\n",
      "[274]\tvalid_0's l2: 2.48698\n",
      "[275]\tvalid_0's l2: 2.48654\n",
      "[276]\tvalid_0's l2: 2.48598\n",
      "[277]\tvalid_0's l2: 2.48588\n",
      "[278]\tvalid_0's l2: 2.48538\n",
      "[279]\tvalid_0's l2: 2.48483\n",
      "[280]\tvalid_0's l2: 2.48477\n",
      "[281]\tvalid_0's l2: 2.48421\n",
      "[282]\tvalid_0's l2: 2.4837\n",
      "[283]\tvalid_0's l2: 2.48316\n",
      "[284]\tvalid_0's l2: 2.48309\n",
      "[285]\tvalid_0's l2: 2.48265\n",
      "[286]\tvalid_0's l2: 2.48212\n",
      "[287]\tvalid_0's l2: 2.48202\n",
      "[288]\tvalid_0's l2: 2.48152\n",
      "[289]\tvalid_0's l2: 2.48144\n",
      "[290]\tvalid_0's l2: 2.48091\n",
      "[291]\tvalid_0's l2: 2.48047\n",
      "[292]\tvalid_0's l2: 2.48041\n",
      "[293]\tvalid_0's l2: 2.47999\n",
      "[294]\tvalid_0's l2: 2.47993\n",
      "[295]\tvalid_0's l2: 2.47942\n",
      "[296]\tvalid_0's l2: 2.47893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[297]\tvalid_0's l2: 2.47847\n",
      "[298]\tvalid_0's l2: 2.4784\n",
      "[299]\tvalid_0's l2: 2.478\n",
      "[300]\tvalid_0's l2: 2.47753\n",
      "[301]\tvalid_0's l2: 2.47725\n",
      "[302]\tvalid_0's l2: 2.47683\n",
      "[303]\tvalid_0's l2: 2.47675\n",
      "[304]\tvalid_0's l2: 2.47636\n",
      "[305]\tvalid_0's l2: 2.47597\n",
      "[306]\tvalid_0's l2: 2.47591\n",
      "[307]\tvalid_0's l2: 2.47579\n",
      "[308]\tvalid_0's l2: 2.4754\n",
      "[309]\tvalid_0's l2: 2.47506\n",
      "[310]\tvalid_0's l2: 2.47479\n",
      "[311]\tvalid_0's l2: 2.47443\n",
      "[312]\tvalid_0's l2: 2.474\n",
      "[313]\tvalid_0's l2: 2.47394\n",
      "[314]\tvalid_0's l2: 2.47359\n",
      "[315]\tvalid_0's l2: 2.47332\n",
      "[316]\tvalid_0's l2: 2.47324\n",
      "[317]\tvalid_0's l2: 2.47285\n",
      "[318]\tvalid_0's l2: 2.47261\n",
      "[319]\tvalid_0's l2: 2.47223\n",
      "[320]\tvalid_0's l2: 2.47187\n",
      "[321]\tvalid_0's l2: 2.47181\n",
      "[322]\tvalid_0's l2: 2.47149\n",
      "[323]\tvalid_0's l2: 2.47142\n",
      "[324]\tvalid_0's l2: 2.47106\n",
      "[325]\tvalid_0's l2: 2.4708\n",
      "[326]\tvalid_0's l2: 2.47074\n",
      "[327]\tvalid_0's l2: 2.4704\n",
      "[328]\tvalid_0's l2: 2.47012\n",
      "[329]\tvalid_0's l2: 2.46978\n",
      "[330]\tvalid_0's l2: 2.46951\n",
      "[331]\tvalid_0's l2: 2.46947\n",
      "[332]\tvalid_0's l2: 2.46916\n",
      "[333]\tvalid_0's l2: 2.46882\n",
      "[334]\tvalid_0's l2: 2.46855\n",
      "[335]\tvalid_0's l2: 2.46825\n",
      "[336]\tvalid_0's l2: 2.46801\n",
      "[337]\tvalid_0's l2: 2.46796\n",
      "[338]\tvalid_0's l2: 2.46766\n",
      "[339]\tvalid_0's l2: 2.46738\n",
      "[340]\tvalid_0's l2: 2.46714\n",
      "[341]\tvalid_0's l2: 2.46691\n",
      "[342]\tvalid_0's l2: 2.46662\n",
      "[343]\tvalid_0's l2: 2.46657\n",
      "[344]\tvalid_0's l2: 2.46629\n",
      "[345]\tvalid_0's l2: 2.46608\n",
      "[346]\tvalid_0's l2: 2.46583\n",
      "[347]\tvalid_0's l2: 2.46553\n",
      "[348]\tvalid_0's l2: 2.46533\n",
      "[349]\tvalid_0's l2: 2.46504\n",
      "[350]\tvalid_0's l2: 2.46478\n",
      "[351]\tvalid_0's l2: 2.46467\n",
      "[352]\tvalid_0's l2: 2.46437\n",
      "[353]\tvalid_0's l2: 2.46408\n",
      "[354]\tvalid_0's l2: 2.46387\n",
      "[355]\tvalid_0's l2: 2.46358\n",
      "[356]\tvalid_0's l2: 2.46336\n",
      "[357]\tvalid_0's l2: 2.46317\n",
      "[358]\tvalid_0's l2: 2.46289\n",
      "[359]\tvalid_0's l2: 2.46285\n",
      "[360]\tvalid_0's l2: 2.46262\n",
      "[361]\tvalid_0's l2: 2.46237\n",
      "[362]\tvalid_0's l2: 2.46216\n",
      "[363]\tvalid_0's l2: 2.46189\n",
      "[364]\tvalid_0's l2: 2.4617\n",
      "[365]\tvalid_0's l2: 2.46148\n",
      "[366]\tvalid_0's l2: 2.46145\n",
      "[367]\tvalid_0's l2: 2.46121\n",
      "[368]\tvalid_0's l2: 2.46097\n",
      "[369]\tvalid_0's l2: 2.46076\n",
      "[370]\tvalid_0's l2: 2.46054\n",
      "[371]\tvalid_0's l2: 2.46034\n",
      "[372]\tvalid_0's l2: 2.46009\n",
      "[373]\tvalid_0's l2: 2.4599\n",
      "[374]\tvalid_0's l2: 2.45964\n",
      "[375]\tvalid_0's l2: 2.45951\n",
      "[376]\tvalid_0's l2: 2.45928\n",
      "[377]\tvalid_0's l2: 2.45908\n",
      "[378]\tvalid_0's l2: 2.45906\n",
      "[379]\tvalid_0's l2: 2.45884\n",
      "[380]\tvalid_0's l2: 2.45868\n",
      "[381]\tvalid_0's l2: 2.45845\n",
      "[382]\tvalid_0's l2: 2.45838\n",
      "[383]\tvalid_0's l2: 2.4582\n",
      "[384]\tvalid_0's l2: 2.45812\n",
      "[385]\tvalid_0's l2: 2.45789\n",
      "[386]\tvalid_0's l2: 2.45775\n",
      "[387]\tvalid_0's l2: 2.45769\n",
      "[388]\tvalid_0's l2: 2.45746\n",
      "[389]\tvalid_0's l2: 2.4573\n",
      "[390]\tvalid_0's l2: 2.45717\n",
      "[391]\tvalid_0's l2: 2.45712\n",
      "[392]\tvalid_0's l2: 2.45693\n",
      "[393]\tvalid_0's l2: 2.45679\n",
      "[394]\tvalid_0's l2: 2.45658\n",
      "[395]\tvalid_0's l2: 2.45645\n",
      "[396]\tvalid_0's l2: 2.45633\n",
      "[397]\tvalid_0's l2: 2.45616\n",
      "[398]\tvalid_0's l2: 2.45611\n",
      "[399]\tvalid_0's l2: 2.4559\n",
      "[400]\tvalid_0's l2: 2.45579\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\tvalid_0's l2: 2.45579\n",
      "fscore        : 0.6035547983912278\n",
      "maeOverFscore : 1.7261039250898074\n",
      "[1]\tvalid_0's l2: 3.17849\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's l2: 3.16051\n",
      "[3]\tvalid_0's l2: 3.1428\n",
      "[4]\tvalid_0's l2: 3.1255\n",
      "[5]\tvalid_0's l2: 3.10844\n",
      "[6]\tvalid_0's l2: 3.09174\n",
      "[7]\tvalid_0's l2: 3.07539\n",
      "[8]\tvalid_0's l2: 3.05933\n",
      "[9]\tvalid_0's l2: 3.04358\n",
      "[10]\tvalid_0's l2: 3.02806\n",
      "[11]\tvalid_0's l2: 3.01319\n",
      "[12]\tvalid_0's l2: 2.99819\n",
      "[13]\tvalid_0's l2: 2.9839\n",
      "[14]\tvalid_0's l2: 2.96983\n",
      "[15]\tvalid_0's l2: 2.95565\n",
      "[16]\tvalid_0's l2: 2.94216\n",
      "[17]\tvalid_0's l2: 2.92856\n",
      "[18]\tvalid_0's l2: 2.91521\n",
      "[19]\tvalid_0's l2: 2.90239\n",
      "[20]\tvalid_0's l2: 2.88948\n",
      "[21]\tvalid_0's l2: 2.87682\n",
      "[22]\tvalid_0's l2: 2.8646\n",
      "[23]\tvalid_0's l2: 2.85271\n",
      "[24]\tvalid_0's l2: 2.84095\n",
      "[25]\tvalid_0's l2: 2.82942\n",
      "[26]\tvalid_0's l2: 2.81817\n",
      "[27]\tvalid_0's l2: 2.80711\n",
      "[28]\tvalid_0's l2: 2.79615\n",
      "[29]\tvalid_0's l2: 2.78518\n",
      "[30]\tvalid_0's l2: 2.77465\n",
      "[31]\tvalid_0's l2: 2.76442\n",
      "[32]\tvalid_0's l2: 2.75432\n",
      "[33]\tvalid_0's l2: 2.74438\n",
      "[34]\tvalid_0's l2: 2.73466\n",
      "[35]\tvalid_0's l2: 2.72482\n",
      "[36]\tvalid_0's l2: 2.71546\n",
      "[37]\tvalid_0's l2: 2.70618\n",
      "[38]\tvalid_0's l2: 2.69721\n",
      "[39]\tvalid_0's l2: 2.68818\n",
      "[40]\tvalid_0's l2: 2.67942\n",
      "[41]\tvalid_0's l2: 2.6708\n",
      "[42]\tvalid_0's l2: 2.66242\n",
      "[43]\tvalid_0's l2: 2.65418\n",
      "[44]\tvalid_0's l2: 2.6459\n",
      "[45]\tvalid_0's l2: 2.6379\n",
      "[46]\tvalid_0's l2: 2.63014\n",
      "[47]\tvalid_0's l2: 2.62233\n",
      "[48]\tvalid_0's l2: 2.61466\n",
      "[49]\tvalid_0's l2: 2.60717\n",
      "[50]\tvalid_0's l2: 2.59993\n",
      "[51]\tvalid_0's l2: 2.59269\n",
      "[52]\tvalid_0's l2: 2.58558\n",
      "[53]\tvalid_0's l2: 2.57861\n",
      "[54]\tvalid_0's l2: 2.5719\n",
      "[55]\tvalid_0's l2: 2.56521\n",
      "[56]\tvalid_0's l2: 2.5586\n",
      "[57]\tvalid_0's l2: 2.55188\n",
      "[58]\tvalid_0's l2: 2.54546\n",
      "[59]\tvalid_0's l2: 2.53921\n",
      "[60]\tvalid_0's l2: 2.53302\n",
      "[61]\tvalid_0's l2: 2.52704\n",
      "[62]\tvalid_0's l2: 2.52108\n",
      "[63]\tvalid_0's l2: 2.51509\n",
      "[64]\tvalid_0's l2: 2.50942\n",
      "[65]\tvalid_0's l2: 2.50373\n",
      "[66]\tvalid_0's l2: 2.49822\n",
      "[67]\tvalid_0's l2: 2.49275\n",
      "[68]\tvalid_0's l2: 2.48725\n",
      "[69]\tvalid_0's l2: 2.48204\n",
      "[70]\tvalid_0's l2: 2.47695\n",
      "[71]\tvalid_0's l2: 2.47182\n",
      "[72]\tvalid_0's l2: 2.46671\n",
      "[73]\tvalid_0's l2: 2.46189\n",
      "[74]\tvalid_0's l2: 2.45706\n",
      "[75]\tvalid_0's l2: 2.45241\n",
      "[76]\tvalid_0's l2: 2.44775\n",
      "[77]\tvalid_0's l2: 2.44314\n",
      "[78]\tvalid_0's l2: 2.43875\n",
      "[79]\tvalid_0's l2: 2.43432\n",
      "[80]\tvalid_0's l2: 2.42998\n",
      "[81]\tvalid_0's l2: 2.42577\n",
      "[82]\tvalid_0's l2: 2.42156\n",
      "[83]\tvalid_0's l2: 2.41738\n",
      "[84]\tvalid_0's l2: 2.41343\n",
      "[85]\tvalid_0's l2: 2.4093\n",
      "[86]\tvalid_0's l2: 2.40538\n",
      "[87]\tvalid_0's l2: 2.40135\n",
      "[88]\tvalid_0's l2: 2.39758\n",
      "[89]\tvalid_0's l2: 2.39371\n",
      "[90]\tvalid_0's l2: 2.38998\n",
      "[91]\tvalid_0's l2: 2.38639\n",
      "[92]\tvalid_0's l2: 2.3827\n",
      "[93]\tvalid_0's l2: 2.37925\n",
      "[94]\tvalid_0's l2: 2.37567\n",
      "[95]\tvalid_0's l2: 2.37229\n",
      "[96]\tvalid_0's l2: 2.3689\n",
      "[97]\tvalid_0's l2: 2.3656\n",
      "[98]\tvalid_0's l2: 2.36227\n",
      "[99]\tvalid_0's l2: 2.35891\n",
      "[100]\tvalid_0's l2: 2.35575\n",
      "[101]\tvalid_0's l2: 2.35255\n",
      "[102]\tvalid_0's l2: 2.34948\n",
      "[103]\tvalid_0's l2: 2.34648\n",
      "[104]\tvalid_0's l2: 2.34344\n",
      "[105]\tvalid_0's l2: 2.34059\n",
      "[106]\tvalid_0's l2: 2.33763\n",
      "[107]\tvalid_0's l2: 2.3348\n",
      "[108]\tvalid_0's l2: 2.33193\n",
      "[109]\tvalid_0's l2: 2.32924\n",
      "[110]\tvalid_0's l2: 2.32638\n",
      "[111]\tvalid_0's l2: 2.32374\n",
      "[112]\tvalid_0's l2: 2.32111\n",
      "[113]\tvalid_0's l2: 2.31857\n",
      "[114]\tvalid_0's l2: 2.31596\n",
      "[115]\tvalid_0's l2: 2.31344\n",
      "[116]\tvalid_0's l2: 2.31108\n",
      "[117]\tvalid_0's l2: 2.30871\n",
      "[118]\tvalid_0's l2: 2.30628\n",
      "[119]\tvalid_0's l2: 2.30392\n",
      "[120]\tvalid_0's l2: 2.30164\n",
      "[121]\tvalid_0's l2: 2.29929\n",
      "[122]\tvalid_0's l2: 2.29698\n",
      "[123]\tvalid_0's l2: 2.29479\n",
      "[124]\tvalid_0's l2: 2.29266\n",
      "[125]\tvalid_0's l2: 2.29057\n",
      "[126]\tvalid_0's l2: 2.28839\n",
      "[127]\tvalid_0's l2: 2.28624\n",
      "[128]\tvalid_0's l2: 2.28415\n",
      "[129]\tvalid_0's l2: 2.28201\n",
      "[130]\tvalid_0's l2: 2.28002\n",
      "[131]\tvalid_0's l2: 2.278\n",
      "[132]\tvalid_0's l2: 2.27607\n",
      "[133]\tvalid_0's l2: 2.27427\n",
      "[134]\tvalid_0's l2: 2.27239\n",
      "[135]\tvalid_0's l2: 2.27047\n",
      "[136]\tvalid_0's l2: 2.26852\n",
      "[137]\tvalid_0's l2: 2.26676\n",
      "[138]\tvalid_0's l2: 2.26493\n",
      "[139]\tvalid_0's l2: 2.26309\n",
      "[140]\tvalid_0's l2: 2.26136\n",
      "[141]\tvalid_0's l2: 2.25961\n",
      "[142]\tvalid_0's l2: 2.2579\n",
      "[143]\tvalid_0's l2: 2.2562\n",
      "[144]\tvalid_0's l2: 2.25456\n",
      "[145]\tvalid_0's l2: 2.25291\n",
      "[146]\tvalid_0's l2: 2.25122\n",
      "[147]\tvalid_0's l2: 2.24964\n",
      "[148]\tvalid_0's l2: 2.24804\n",
      "[149]\tvalid_0's l2: 2.2465\n",
      "[150]\tvalid_0's l2: 2.24494\n",
      "[151]\tvalid_0's l2: 2.24353\n",
      "[152]\tvalid_0's l2: 2.24204\n",
      "[153]\tvalid_0's l2: 2.24054\n",
      "[154]\tvalid_0's l2: 2.23908\n",
      "[155]\tvalid_0's l2: 2.23772\n",
      "[156]\tvalid_0's l2: 2.23631\n",
      "[157]\tvalid_0's l2: 2.23501\n",
      "[158]\tvalid_0's l2: 2.23355\n",
      "[159]\tvalid_0's l2: 2.23218\n",
      "[160]\tvalid_0's l2: 2.23088\n",
      "[161]\tvalid_0's l2: 2.22957\n",
      "[162]\tvalid_0's l2: 2.22829\n",
      "[163]\tvalid_0's l2: 2.22697\n",
      "[164]\tvalid_0's l2: 2.22571\n",
      "[165]\tvalid_0's l2: 2.22455\n",
      "[166]\tvalid_0's l2: 2.22335\n",
      "[167]\tvalid_0's l2: 2.22214\n",
      "[168]\tvalid_0's l2: 2.22093\n",
      "[169]\tvalid_0's l2: 2.21975\n",
      "[170]\tvalid_0's l2: 2.21865\n",
      "[171]\tvalid_0's l2: 2.21751\n",
      "[172]\tvalid_0's l2: 2.21638\n",
      "[173]\tvalid_0's l2: 2.21525\n",
      "[174]\tvalid_0's l2: 2.21415\n",
      "[175]\tvalid_0's l2: 2.21297\n",
      "[176]\tvalid_0's l2: 2.21191\n",
      "[177]\tvalid_0's l2: 2.21086\n",
      "[178]\tvalid_0's l2: 2.20983\n",
      "[179]\tvalid_0's l2: 2.2088\n",
      "[180]\tvalid_0's l2: 2.20776\n",
      "[181]\tvalid_0's l2: 2.20675\n",
      "[182]\tvalid_0's l2: 2.20579\n",
      "[183]\tvalid_0's l2: 2.2048\n",
      "[184]\tvalid_0's l2: 2.20382\n",
      "[185]\tvalid_0's l2: 2.20289\n",
      "[186]\tvalid_0's l2: 2.20195\n",
      "[187]\tvalid_0's l2: 2.201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[188]\tvalid_0's l2: 2.2001\n",
      "[189]\tvalid_0's l2: 2.19914\n",
      "[190]\tvalid_0's l2: 2.19822\n",
      "[191]\tvalid_0's l2: 2.19735\n",
      "[192]\tvalid_0's l2: 2.19645\n",
      "[193]\tvalid_0's l2: 2.19555\n",
      "[194]\tvalid_0's l2: 2.19469\n",
      "[195]\tvalid_0's l2: 2.19386\n",
      "[196]\tvalid_0's l2: 2.19302\n",
      "[197]\tvalid_0's l2: 2.19223\n",
      "[198]\tvalid_0's l2: 2.19136\n",
      "[199]\tvalid_0's l2: 2.19058\n",
      "[200]\tvalid_0's l2: 2.18973\n",
      "[201]\tvalid_0's l2: 2.18888\n",
      "[202]\tvalid_0's l2: 2.18815\n",
      "[203]\tvalid_0's l2: 2.18734\n",
      "[204]\tvalid_0's l2: 2.18653\n",
      "[205]\tvalid_0's l2: 2.18576\n",
      "[206]\tvalid_0's l2: 2.18491\n",
      "[207]\tvalid_0's l2: 2.18421\n",
      "[208]\tvalid_0's l2: 2.18342\n",
      "[209]\tvalid_0's l2: 2.18256\n",
      "[210]\tvalid_0's l2: 2.18174\n",
      "[211]\tvalid_0's l2: 2.18095\n",
      "[212]\tvalid_0's l2: 2.18024\n",
      "[213]\tvalid_0's l2: 2.17947\n",
      "[214]\tvalid_0's l2: 2.17872\n",
      "[215]\tvalid_0's l2: 2.17798\n",
      "[216]\tvalid_0's l2: 2.17734\n",
      "[217]\tvalid_0's l2: 2.17667\n",
      "[218]\tvalid_0's l2: 2.17606\n",
      "[219]\tvalid_0's l2: 2.17541\n",
      "[220]\tvalid_0's l2: 2.17467\n",
      "[221]\tvalid_0's l2: 2.17407\n",
      "[222]\tvalid_0's l2: 2.17347\n",
      "[223]\tvalid_0's l2: 2.17278\n",
      "[224]\tvalid_0's l2: 2.17209\n",
      "[225]\tvalid_0's l2: 2.17145\n",
      "[226]\tvalid_0's l2: 2.17089\n",
      "[227]\tvalid_0's l2: 2.17023\n",
      "[228]\tvalid_0's l2: 2.16956\n",
      "[229]\tvalid_0's l2: 2.16909\n",
      "[230]\tvalid_0's l2: 2.16845\n",
      "[231]\tvalid_0's l2: 2.16798\n",
      "[232]\tvalid_0's l2: 2.16729\n",
      "[233]\tvalid_0's l2: 2.16678\n",
      "[234]\tvalid_0's l2: 2.16614\n",
      "[235]\tvalid_0's l2: 2.16569\n",
      "[236]\tvalid_0's l2: 2.16504\n",
      "[237]\tvalid_0's l2: 2.1646\n",
      "[238]\tvalid_0's l2: 2.16405\n",
      "[239]\tvalid_0's l2: 2.16357\n",
      "[240]\tvalid_0's l2: 2.16314\n",
      "[241]\tvalid_0's l2: 2.16259\n",
      "[242]\tvalid_0's l2: 2.16215\n",
      "[243]\tvalid_0's l2: 2.16161\n",
      "[244]\tvalid_0's l2: 2.16117\n",
      "[245]\tvalid_0's l2: 2.1606\n",
      "[246]\tvalid_0's l2: 2.16023\n",
      "[247]\tvalid_0's l2: 2.15969\n",
      "[248]\tvalid_0's l2: 2.15925\n",
      "[249]\tvalid_0's l2: 2.15875\n",
      "[250]\tvalid_0's l2: 2.15822\n",
      "[251]\tvalid_0's l2: 2.15785\n",
      "[252]\tvalid_0's l2: 2.15738\n",
      "[253]\tvalid_0's l2: 2.157\n",
      "[254]\tvalid_0's l2: 2.15654\n",
      "[255]\tvalid_0's l2: 2.15617\n",
      "[256]\tvalid_0's l2: 2.15571\n",
      "[257]\tvalid_0's l2: 2.15533\n",
      "[258]\tvalid_0's l2: 2.15482\n",
      "[259]\tvalid_0's l2: 2.15442\n",
      "[260]\tvalid_0's l2: 2.15391\n",
      "[261]\tvalid_0's l2: 2.15343\n",
      "[262]\tvalid_0's l2: 2.15311\n",
      "[263]\tvalid_0's l2: 2.15266\n",
      "[264]\tvalid_0's l2: 2.15217\n",
      "[265]\tvalid_0's l2: 2.15181\n",
      "[266]\tvalid_0's l2: 2.15142\n",
      "[267]\tvalid_0's l2: 2.15111\n",
      "[268]\tvalid_0's l2: 2.15078\n",
      "[269]\tvalid_0's l2: 2.15034\n",
      "[270]\tvalid_0's l2: 2.14997\n",
      "[271]\tvalid_0's l2: 2.14953\n",
      "[272]\tvalid_0's l2: 2.14924\n",
      "[273]\tvalid_0's l2: 2.14879\n",
      "[274]\tvalid_0's l2: 2.14851\n",
      "[275]\tvalid_0's l2: 2.14817\n",
      "[276]\tvalid_0's l2: 2.14785\n",
      "[277]\tvalid_0's l2: 2.14758\n",
      "[278]\tvalid_0's l2: 2.1472\n",
      "[279]\tvalid_0's l2: 2.14688\n",
      "[280]\tvalid_0's l2: 2.14648\n",
      "[281]\tvalid_0's l2: 2.14613\n",
      "[282]\tvalid_0's l2: 2.14576\n",
      "[283]\tvalid_0's l2: 2.14552\n",
      "[284]\tvalid_0's l2: 2.14521\n",
      "[285]\tvalid_0's l2: 2.14482\n",
      "[286]\tvalid_0's l2: 2.14458\n",
      "[287]\tvalid_0's l2: 2.14417\n",
      "[288]\tvalid_0's l2: 2.14393\n",
      "[289]\tvalid_0's l2: 2.14356\n",
      "[290]\tvalid_0's l2: 2.14329\n",
      "[291]\tvalid_0's l2: 2.14297\n",
      "[292]\tvalid_0's l2: 2.14272\n",
      "[293]\tvalid_0's l2: 2.14234\n",
      "[294]\tvalid_0's l2: 2.14213\n",
      "[295]\tvalid_0's l2: 2.14188\n",
      "[296]\tvalid_0's l2: 2.14158\n",
      "[297]\tvalid_0's l2: 2.14126\n",
      "[298]\tvalid_0's l2: 2.14103\n",
      "[299]\tvalid_0's l2: 2.14069\n",
      "[300]\tvalid_0's l2: 2.14039\n",
      "[301]\tvalid_0's l2: 2.14015\n",
      "[302]\tvalid_0's l2: 2.13983\n",
      "[303]\tvalid_0's l2: 2.13954\n",
      "[304]\tvalid_0's l2: 2.13929\n",
      "[305]\tvalid_0's l2: 2.139\n",
      "[306]\tvalid_0's l2: 2.13881\n",
      "[307]\tvalid_0's l2: 2.13857\n",
      "[308]\tvalid_0's l2: 2.13829\n",
      "[309]\tvalid_0's l2: 2.13809\n",
      "[310]\tvalid_0's l2: 2.13787\n",
      "[311]\tvalid_0's l2: 2.13764\n",
      "[312]\tvalid_0's l2: 2.13732\n",
      "[313]\tvalid_0's l2: 2.13699\n",
      "[314]\tvalid_0's l2: 2.13671\n",
      "[315]\tvalid_0's l2: 2.13648\n",
      "[316]\tvalid_0's l2: 2.1362\n",
      "[317]\tvalid_0's l2: 2.13598\n",
      "[318]\tvalid_0's l2: 2.13561\n",
      "[319]\tvalid_0's l2: 2.1354\n",
      "[320]\tvalid_0's l2: 2.13518\n",
      "[321]\tvalid_0's l2: 2.13484\n",
      "[322]\tvalid_0's l2: 2.1346\n",
      "[323]\tvalid_0's l2: 2.1344\n",
      "[324]\tvalid_0's l2: 2.13421\n",
      "[325]\tvalid_0's l2: 2.13396\n",
      "[326]\tvalid_0's l2: 2.13376\n",
      "[327]\tvalid_0's l2: 2.13354\n",
      "[328]\tvalid_0's l2: 2.13334\n",
      "[329]\tvalid_0's l2: 2.13311\n",
      "[330]\tvalid_0's l2: 2.13277\n",
      "[331]\tvalid_0's l2: 2.1326\n",
      "[332]\tvalid_0's l2: 2.1324\n",
      "[333]\tvalid_0's l2: 2.13219\n",
      "[334]\tvalid_0's l2: 2.13202\n",
      "[335]\tvalid_0's l2: 2.13173\n",
      "[336]\tvalid_0's l2: 2.13152\n",
      "[337]\tvalid_0's l2: 2.13135\n",
      "[338]\tvalid_0's l2: 2.13116\n",
      "[339]\tvalid_0's l2: 2.13094\n",
      "[340]\tvalid_0's l2: 2.13076\n",
      "[341]\tvalid_0's l2: 2.13048\n",
      "[342]\tvalid_0's l2: 2.1303\n",
      "[343]\tvalid_0's l2: 2.13003\n",
      "[344]\tvalid_0's l2: 2.12988\n",
      "[345]\tvalid_0's l2: 2.12967\n",
      "[346]\tvalid_0's l2: 2.12948\n",
      "[347]\tvalid_0's l2: 2.12919\n",
      "[348]\tvalid_0's l2: 2.12904\n",
      "[349]\tvalid_0's l2: 2.12879\n",
      "[350]\tvalid_0's l2: 2.12861\n",
      "[351]\tvalid_0's l2: 2.12837\n",
      "[352]\tvalid_0's l2: 2.12818\n",
      "[353]\tvalid_0's l2: 2.12795\n",
      "[354]\tvalid_0's l2: 2.12774\n",
      "[355]\tvalid_0's l2: 2.12753\n",
      "[356]\tvalid_0's l2: 2.12736\n",
      "[357]\tvalid_0's l2: 2.12713\n",
      "[358]\tvalid_0's l2: 2.12692\n",
      "[359]\tvalid_0's l2: 2.12669\n",
      "[360]\tvalid_0's l2: 2.12653\n",
      "[361]\tvalid_0's l2: 2.12633\n",
      "[362]\tvalid_0's l2: 2.12606\n",
      "[363]\tvalid_0's l2: 2.12584\n",
      "[364]\tvalid_0's l2: 2.1256\n",
      "[365]\tvalid_0's l2: 2.12542\n",
      "[366]\tvalid_0's l2: 2.12515\n",
      "[367]\tvalid_0's l2: 2.12492\n",
      "[368]\tvalid_0's l2: 2.12469\n",
      "[369]\tvalid_0's l2: 2.12447\n",
      "[370]\tvalid_0's l2: 2.12421\n",
      "[371]\tvalid_0's l2: 2.1241\n",
      "[372]\tvalid_0's l2: 2.12385\n",
      "[373]\tvalid_0's l2: 2.12364\n",
      "[374]\tvalid_0's l2: 2.12336\n",
      "[375]\tvalid_0's l2: 2.1231\n",
      "[376]\tvalid_0's l2: 2.1229\n",
      "[377]\tvalid_0's l2: 2.12267\n",
      "[378]\tvalid_0's l2: 2.12247\n",
      "[379]\tvalid_0's l2: 2.12223\n",
      "[380]\tvalid_0's l2: 2.12206\n",
      "[381]\tvalid_0's l2: 2.12196\n",
      "[382]\tvalid_0's l2: 2.12176\n",
      "[383]\tvalid_0's l2: 2.12159\n",
      "[384]\tvalid_0's l2: 2.12143\n",
      "[385]\tvalid_0's l2: 2.12128\n",
      "[386]\tvalid_0's l2: 2.12105\n",
      "[387]\tvalid_0's l2: 2.12087\n",
      "[388]\tvalid_0's l2: 2.12078\n",
      "[389]\tvalid_0's l2: 2.12062\n",
      "[390]\tvalid_0's l2: 2.12047\n",
      "[391]\tvalid_0's l2: 2.12039\n",
      "[392]\tvalid_0's l2: 2.1203\n",
      "[393]\tvalid_0's l2: 2.12013\n",
      "[394]\tvalid_0's l2: 2.11998\n",
      "[395]\tvalid_0's l2: 2.11982\n",
      "[396]\tvalid_0's l2: 2.11974\n",
      "[397]\tvalid_0's l2: 2.11958\n",
      "[398]\tvalid_0's l2: 2.1195\n",
      "[399]\tvalid_0's l2: 2.11936\n",
      "[400]\tvalid_0's l2: 2.11919\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\tvalid_0's l2: 2.11919\n",
      "fscore        : 0.5702102319429913\n",
      "maeOverFscore : 1.7191791666443437\n",
      "[1]\tvalid_0's l2: 3.71419\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's l2: 3.69197\n",
      "[3]\tvalid_0's l2: 3.67016\n",
      "[4]\tvalid_0's l2: 3.6488\n",
      "[5]\tvalid_0's l2: 3.62794\n",
      "[6]\tvalid_0's l2: 3.60751\n",
      "[7]\tvalid_0's l2: 3.58709\n",
      "[8]\tvalid_0's l2: 3.56677\n",
      "[9]\tvalid_0's l2: 3.54655\n",
      "[10]\tvalid_0's l2: 3.52773\n",
      "[11]\tvalid_0's l2: 3.5086\n",
      "[12]\tvalid_0's l2: 3.48949\n",
      "[13]\tvalid_0's l2: 3.47129\n",
      "[14]\tvalid_0's l2: 3.45362\n",
      "[15]\tvalid_0's l2: 3.43611\n",
      "[16]\tvalid_0's l2: 3.41868\n",
      "[17]\tvalid_0's l2: 3.4021\n",
      "[18]\tvalid_0's l2: 3.38569\n",
      "[19]\tvalid_0's l2: 3.36947\n",
      "[20]\tvalid_0's l2: 3.35377\n",
      "[21]\tvalid_0's l2: 3.33796\n",
      "[22]\tvalid_0's l2: 3.3227\n",
      "[23]\tvalid_0's l2: 3.30786\n",
      "[24]\tvalid_0's l2: 3.29313\n",
      "[25]\tvalid_0's l2: 3.27874\n",
      "[26]\tvalid_0's l2: 3.26453\n",
      "[27]\tvalid_0's l2: 3.25078\n",
      "[28]\tvalid_0's l2: 3.23738\n",
      "[29]\tvalid_0's l2: 3.22406\n",
      "[30]\tvalid_0's l2: 3.21099\n",
      "[31]\tvalid_0's l2: 3.19817\n",
      "[32]\tvalid_0's l2: 3.1857\n",
      "[33]\tvalid_0's l2: 3.17306\n",
      "[34]\tvalid_0's l2: 3.16098\n",
      "[35]\tvalid_0's l2: 3.14915\n",
      "[36]\tvalid_0's l2: 3.13718\n",
      "[37]\tvalid_0's l2: 3.12577\n",
      "[38]\tvalid_0's l2: 3.11455\n",
      "[39]\tvalid_0's l2: 3.10361\n",
      "[40]\tvalid_0's l2: 3.09265\n",
      "[41]\tvalid_0's l2: 3.0821\n",
      "[42]\tvalid_0's l2: 3.07166\n",
      "[43]\tvalid_0's l2: 3.0614\n",
      "[44]\tvalid_0's l2: 3.05129\n",
      "[45]\tvalid_0's l2: 3.04148\n",
      "[46]\tvalid_0's l2: 3.03175\n",
      "[47]\tvalid_0's l2: 3.02233\n",
      "[48]\tvalid_0's l2: 3.01293\n",
      "[49]\tvalid_0's l2: 3.00374\n",
      "[50]\tvalid_0's l2: 2.99471\n",
      "[51]\tvalid_0's l2: 2.98591\n",
      "[52]\tvalid_0's l2: 2.97724\n",
      "[53]\tvalid_0's l2: 2.96867\n",
      "[54]\tvalid_0's l2: 2.96037\n",
      "[55]\tvalid_0's l2: 2.95216\n",
      "[56]\tvalid_0's l2: 2.94418\n",
      "[57]\tvalid_0's l2: 2.93634\n",
      "[58]\tvalid_0's l2: 2.92851\n",
      "[59]\tvalid_0's l2: 2.92098\n",
      "[60]\tvalid_0's l2: 2.91353\n",
      "[61]\tvalid_0's l2: 2.90626\n",
      "[62]\tvalid_0's l2: 2.8991\n",
      "[63]\tvalid_0's l2: 2.89207\n",
      "[64]\tvalid_0's l2: 2.88504\n",
      "[65]\tvalid_0's l2: 2.87829\n",
      "[66]\tvalid_0's l2: 2.87158\n",
      "[67]\tvalid_0's l2: 2.86513\n",
      "[68]\tvalid_0's l2: 2.85855\n",
      "[69]\tvalid_0's l2: 2.8522\n",
      "[70]\tvalid_0's l2: 2.84595\n",
      "[71]\tvalid_0's l2: 2.83968\n",
      "[72]\tvalid_0's l2: 2.83359\n",
      "[73]\tvalid_0's l2: 2.82764\n",
      "[74]\tvalid_0's l2: 2.82201\n",
      "[75]\tvalid_0's l2: 2.81638\n",
      "[76]\tvalid_0's l2: 2.81068\n",
      "[77]\tvalid_0's l2: 2.80514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78]\tvalid_0's l2: 2.79963\n",
      "[79]\tvalid_0's l2: 2.79426\n",
      "[80]\tvalid_0's l2: 2.789\n",
      "[81]\tvalid_0's l2: 2.78377\n",
      "[82]\tvalid_0's l2: 2.77867\n",
      "[83]\tvalid_0's l2: 2.77382\n",
      "[84]\tvalid_0's l2: 2.7689\n",
      "[85]\tvalid_0's l2: 2.76407\n",
      "[86]\tvalid_0's l2: 2.75945\n",
      "[87]\tvalid_0's l2: 2.75474\n",
      "[88]\tvalid_0's l2: 2.75015\n",
      "[89]\tvalid_0's l2: 2.74564\n",
      "[90]\tvalid_0's l2: 2.74126\n",
      "[91]\tvalid_0's l2: 2.73688\n",
      "[92]\tvalid_0's l2: 2.73273\n",
      "[93]\tvalid_0's l2: 2.72858\n",
      "[94]\tvalid_0's l2: 2.72443\n",
      "[95]\tvalid_0's l2: 2.72034\n",
      "[96]\tvalid_0's l2: 2.71633\n",
      "[97]\tvalid_0's l2: 2.71248\n",
      "[98]\tvalid_0's l2: 2.70857\n",
      "[99]\tvalid_0's l2: 2.70474\n",
      "[100]\tvalid_0's l2: 2.70088\n",
      "[101]\tvalid_0's l2: 2.69722\n",
      "[102]\tvalid_0's l2: 2.69357\n",
      "[103]\tvalid_0's l2: 2.69012\n",
      "[104]\tvalid_0's l2: 2.68661\n",
      "[105]\tvalid_0's l2: 2.68316\n",
      "[106]\tvalid_0's l2: 2.67979\n",
      "[107]\tvalid_0's l2: 2.6765\n",
      "[108]\tvalid_0's l2: 2.67323\n",
      "[109]\tvalid_0's l2: 2.67009\n",
      "[110]\tvalid_0's l2: 2.66695\n",
      "[111]\tvalid_0's l2: 2.66381\n",
      "[112]\tvalid_0's l2: 2.66082\n",
      "[113]\tvalid_0's l2: 2.65779\n",
      "[114]\tvalid_0's l2: 2.65488\n",
      "[115]\tvalid_0's l2: 2.65169\n",
      "[116]\tvalid_0's l2: 2.64887\n",
      "[117]\tvalid_0's l2: 2.64594\n",
      "[118]\tvalid_0's l2: 2.64321\n",
      "[119]\tvalid_0's l2: 2.64037\n",
      "[120]\tvalid_0's l2: 2.63773\n",
      "[121]\tvalid_0's l2: 2.63488\n",
      "[122]\tvalid_0's l2: 2.63234\n",
      "[123]\tvalid_0's l2: 2.62968\n",
      "[124]\tvalid_0's l2: 2.62725\n",
      "[125]\tvalid_0's l2: 2.62476\n",
      "[126]\tvalid_0's l2: 2.62238\n",
      "[127]\tvalid_0's l2: 2.61987\n",
      "[128]\tvalid_0's l2: 2.61755\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=4, random_state=7, shuffle=False)\n",
    "scores = list()\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(kfold.split(data)):\n",
    "    clf = lgb.LGBMRegressor(boosting_type='gbdt', num_leaves=31, max_depth=- 1, learning_rate=0.01, \\\n",
    "                             n_estimators=400, subsample_for_bin=200000, objective=None, class_weight=None, \\\n",
    "                             min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, \\\n",
    "                             subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, \\\n",
    "                             n_jobs=- 1, silent=True, importance_type='split')\n",
    "    \n",
    "#     train = lgb.Dataset(X[train_idx, :], Y[train_idx, :])\n",
    "#     val = lgb.Dataset(X[val_idx, :], Y[val_idx, :])\n",
    "\n",
    "    clf.fit(X[train_idx, :], Y[train_idx, 0], eval_set=[(X[val_idx, :], Y[val_idx, 0])], \\\n",
    "            early_stopping_rounds=100, \\\n",
    "            verbose=True)\n",
    "\n",
    "#     clf = lgb.train(params, train, valid_sets=val, \\\n",
    "#             early_stopping_rounds=100, \\\n",
    "#             verbose_eval=True)\n",
    "    \n",
    "#     clf.save_model(os.path.join(model_path, f'lgb_{i}.txt'), \\\n",
    "#                    num_iteration=clf.best_iteration)\n",
    "    \n",
    "    scores.append(score(clf.predict(X[val_idx, :]), Y[val_idx, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_value, mae_value in scores:\n",
    "    print(f\"fscore : {f_value} \\t maeOverFscore : {mae_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "lgb.plot_importance(clf, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(clf, name, preprocess=None):\n",
    "    x_test = reshape(load_data('test'))\n",
    "    \n",
    "    pred = clf.predict(x_test)\n",
    "\n",
    "    submission = pd.read_csv(os.path.join(data_path, 'sample_submission.csv'))\n",
    "    submission.iloc[:, 1:] = pred.reshape(-1, 1600)\n",
    "\n",
    "    submission.to_csv(os.path.join(submit_path, f'{name}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(clf, 'lightbgm_all_features_train_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMRegressor(boosting_type='gbdt', num_leaves=31, max_depth=- 1, learning_rate=0.01, \\\n",
    "                         n_estimators=400, subsample_for_bin=200000, objective=None, class_weight=None, \\\n",
    "                         min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, \\\n",
    "                         subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, \\\n",
    "                         n_jobs=- 1, silent=True, importance_type='split')\n",
    "\n",
    "clf.fit(X, Y.reshape(-1), \\\n",
    "        early_stopping_rounds=100, \\\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(clf, 'lightbgm_all_features_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightbgm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightbgm train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'learning_rate': 0.01, 'max_depth': -1, 'boosting': 'gbdt', \n",
    "          'objective': 'regression', 'metric': 'mae', 'is_training_metric': True, \n",
    "          'num_leaves': 1024, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, \n",
    "          'bagging_freq': 5, 'seed':7}\n",
    "\n",
    "model = lgb.train(params, train, 1000, val, verbose_eval=10, \\\n",
    "                  early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_val)\n",
    "\n",
    "score(y_val, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightbgm LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm.LGBMRegressor(boosting_type='gbdt', num_leaves=31, max_depth=- 1, learning_rate=0.1, \\\n",
    "#                              n_estimators=100, subsample_for_bin=200000, objective=None, class_weight=None, \\\n",
    "#                              min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, \\\n",
    "#                              subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, \\\n",
    "#                              n_jobs=- 1, silent=True, importance_type='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMRegressor(boosting_type='gbdt', num_leaves=31, max_depth=- 1, learning_rate=0.01, \\\n",
    "                             n_estimators=400, subsample_for_bin=200000, objective=None, class_weight=None, \\\n",
    "                             min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, \\\n",
    "                             subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, \\\n",
    "                             n_jobs=- 1, silent=True, importance_type='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit(X, y, sample_weight=None, init_score=None, eval_set=None, eval_names=None, \\\n",
    "#     eval_sample_weight=None, eval_init_score=None, eval_metric=None, \\\n",
    "#     early_stopping_rounds=None, verbose=True, feature_name='auto', \\\n",
    "#     categorical_feature='auto', callbacks=None, init_model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train, y_train, eval_set=[(x_val, y_val)], \\\n",
    "        eval_metric=maeOverFscore_sklearn, early_stopping_rounds=100, \\\n",
    "        verbose=True, eval_names='maeOverFscore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=4, random_state=7, shuffle=True)\n",
    "\n",
    "for (train_idx, val_idx) in kfold.split(Y):\n",
    "    ridge = Ridge(alpha=10.0).fit(X[train_idx, :], Y[train_idx])\n",
    "    \n",
    "    score(Y[val_idx], ridge.predict(X[val_idx, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "lgb.plot_importance(model, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_param = {\n",
    "#     'objective': 'regression',\n",
    "#     'metrics': maeOverFscore_sklearn,\n",
    "#     'learning_rate' : 0.01,\n",
    "#     'eval_metric': maeOverFscore_sklearn,\n",
    "#     'early_stopping_rounds' : 100,\n",
    "#     'eval_set': val_data,\n",
    "#     'verbose': True,\n",
    "#     'stratified':False,\n",
    "#     'verbose_eval': 10,\n",
    "#     'nfold': 5,\n",
    "#     'num_boost_round': 99999,\n",
    "# }\n",
    "\n",
    "# cv_result = lgb.cv(\n",
    "#     lgb_param,\n",
    "#     train_data\n",
    "# )\n",
    "\n",
    "# lgb_model = lgb.train(\n",
    "#   lgb_param,\n",
    "#   train_data,\n",
    "#   num_boost_round=len(cv_result['l1-mean'])\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(clf, name, preprocess=None):\n",
    "    x_test = reshape(load_data('test'))\n",
    "    \n",
    "    if preprocess is not None:\n",
    "        x_test = preprocess.transform(x_test)\n",
    "        print(\"transform\")\n",
    "    \n",
    "    pred = clf.predict(x_test)\n",
    "\n",
    "    submission = pd.read_csv(os.path.join(data_path, 'sample_submission.csv'))\n",
    "    submission.iloc[:, 1:] = pred.reshape(-1, 1600)\n",
    "\n",
    "    submission.to_csv(os.path.join(submit_path, f'{name}.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(lgb_model, 'lightbgm_selectK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://dacon.io/competitions/official/235591/mysubmission/\n",
    "- D:\\인공지능_공모전\\github\\submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
