{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score, make_scorer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred) :\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    \n",
    "    y_true = y_true.reshape(1, -1)[0]\n",
    "    y_pred = y_pred.reshape(1, -1)[0]\n",
    "    over_threshold = y_true >= 0.1\n",
    "    \n",
    "    return np.mean(np.abs(y_true[over_threshold] - y_pred[over_threshold]))\n",
    "\n",
    "def fscore(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    \n",
    "    y_true = y_true.reshape(1, -1)[0]\n",
    "    y_pred = y_pred.reshape(1, -1)[0]\n",
    "    remove_NAs = y_true >= 0\n",
    "    \n",
    "    y_true = np.where(y_true[remove_NAs] >= 0.1, 1, 0)\n",
    "    y_pred = np.where(y_pred[remove_NAs] >= 0.1, 1, 0)\n",
    "    \n",
    "    return (f1_score(y_true, y_pred))\n",
    "\n",
    "def maeOverFscore(y_true, y_pred):\n",
    "    return mae(y_true, y_pred) / (fscore(y_true, y_pred) + 1e-07)\n",
    "\n",
    "def score(y_val, pred):\n",
    "    print(f\"fscore        : {fscore(y_val, pred)}\")\n",
    "    print(f\"maeOverFscore : {maeOverFscore(y_val, pred)}\")\n",
    "\n",
    "fscore_sklearn = make_scorer(fscore)\n",
    "maeOverFscore_sklearn = make_scorer(maeOverFscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = os.getcwd()\n",
    "data_path = os.path.join(base, 'data')\n",
    "submit_path = os.path.join(base, 'submit')\n",
    "\n",
    "def load_data(name):\n",
    "    return np.load(os.path.join(data_path, f\"{name}.npy\"))\n",
    "\n",
    "# def load(name):\n",
    "#     if name == \"test\" :\n",
    "#         return load_data('x', 'test')\n",
    "#     return (load_data(f'x_{name}'), load_data(f'y_{name}'))\n",
    "\n",
    "def reshape(data):\n",
    "    return data.reshape(data.shape[0] * 40 * 40, data.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121608234, 15)\n"
     ]
    }
   ],
   "source": [
    "data = load_data('EDA')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select K\n",
    "![img](feacture_selection.PNG)\n",
    "\n",
    "### selectK 7\n",
    "- [False, False,  True,  True,  True,  True,  True,  True, False, False, False, False, False, True]\n",
    "\n",
    "### selectK 8\n",
    "- [False, False,  True,  True,  True,  True,  True,  True, False, False, False, True, False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectK_7 = [2, 3, 4, 5, 6, 7, 13]\n",
    "selectK_8 = [2, 3, 4, 5, 6, 7, 11, 13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seperate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, selectK_8]\n",
    "Y = data[:, -1]\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightbgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = lgb.Dataset(x_train, y_train)\n",
    "val = lgb.Dataset(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightbgm train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[10]\tvalid_0's l1: 0.146157\n",
      "[20]\tvalid_0's l1: 0.146157\n",
      "[30]\tvalid_0's l1: 0.146157\n",
      "[40]\tvalid_0's l1: 0.146157\n",
      "[50]\tvalid_0's l1: 0.146157\n",
      "[60]\tvalid_0's l1: 0.146157\n",
      "[70]\tvalid_0's l1: 0.146157\n",
      "[80]\tvalid_0's l1: 0.146157\n",
      "[90]\tvalid_0's l1: 0.146157\n",
      "[100]\tvalid_0's l1: 0.146157\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's l1: 0.146157\n"
     ]
    }
   ],
   "source": [
    "params = {'learning_rate': 0.01, 'max_depth': -1, 'boosting': 'gbdt', \n",
    "          'objective': 'regression', 'metric': 'mae', 'is_training_metric': True, \n",
    "          'num_leaves': 1024, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, \n",
    "          'bagging_freq': 5, 'seed':7}\n",
    "\n",
    "model = lgb.train(params, train, 1000, val, verbose_eval=10, \\\n",
    "                  early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fscore        : 0.0\n",
      "maeOverFscore : 21738683.940531477\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_val)\n",
    "\n",
    "score(y_val, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightbgm LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm.LGBMRegressor(boosting_type='gbdt', num_leaves=31, max_depth=- 1, learning_rate=0.1, \\\n",
    "#                              n_estimators=100, subsample_for_bin=200000, objective=None, class_weight=None, \\\n",
    "#                              min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, \\\n",
    "#                              subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, \\\n",
    "#                              n_jobs=- 1, silent=True, importance_type='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMRegressor(boosting_type='gbdt', num_leaves=31, max_depth=- 1, learning_rate=0.01, \\\n",
    "                             n_estimators=400, subsample_for_bin=200000, objective=None, class_weight=None, \\\n",
    "                             min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, \\\n",
    "                             subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, \\\n",
    "                             n_jobs=- 1, silent=True, importance_type='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit(X, y, sample_weight=None, init_score=None, eval_set=None, eval_names=None, \\\n",
    "#     eval_sample_weight=None, eval_init_score=None, eval_metric=None, \\\n",
    "#     early_stopping_rounds=None, verbose=True, feature_name='auto', \\\n",
    "#     categorical_feature='auto', callbacks=None, init_model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train, y_train, eval_set=[(x_val, y_val)], \\\n",
    "        eval_metric=maeOverFscore_sklearn, early_stopping_rounds=100, \\\n",
    "        verbose=True, eval_names='maeOverFscore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=4, random_state=7, shuffle=True)\n",
    "\n",
    "for (train_idx, val_idx) in kfold.split(Y):\n",
    "    ridge = Ridge(alpha=10.0).fit(X[train_idx, :], Y[train_idx])\n",
    "    \n",
    "    score(Y[val_idx], ridge.predict(X[val_idx, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "lgb.plot_importance(model, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_param = {\n",
    "#     'objective': 'regression',\n",
    "#     'metrics': maeOverFscore_sklearn,\n",
    "#     'learning_rate' : 0.01,\n",
    "#     'eval_metric': maeOverFscore_sklearn,\n",
    "#     'early_stopping_rounds' : 100,\n",
    "#     'eval_set': val_data,\n",
    "#     'verbose': True,\n",
    "#     'stratified':False,\n",
    "#     'verbose_eval': 10,\n",
    "#     'nfold': 5,\n",
    "#     'num_boost_round': 99999,\n",
    "# }\n",
    "\n",
    "# cv_result = lgb.cv(\n",
    "#     lgb_param,\n",
    "#     train_data\n",
    "# )\n",
    "\n",
    "# lgb_model = lgb.train(\n",
    "#   lgb_param,\n",
    "#   train_data,\n",
    "#   num_boost_round=len(cv_result['l1-mean'])\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(clf, name, preprocess=None):\n",
    "    x_test = reshape(load_data('test'))\n",
    "    \n",
    "    if preprocess is not None:\n",
    "        x_test = preprocess.transform(x_test)\n",
    "        print(\"transform\")\n",
    "    \n",
    "    pred = clf.predict(x_test)\n",
    "\n",
    "    submission = pd.read_csv(os.path.join(data_path, 'sample_submission.csv'))\n",
    "    submission.iloc[:, 1:] = pred.reshape(-1, 1600)\n",
    "\n",
    "    submission.to_csv(os.path.join(submit_path, f'{name}.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform\n"
     ]
    }
   ],
   "source": [
    "submit(lgb_model, 'lightbgm_selectK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://dacon.io/competitions/official/235591/mysubmission/\n",
    "- D:\\인공지능_공모전\\github\\submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
