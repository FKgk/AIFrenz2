{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache using fc-list. This may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score, make_scorer\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred) :\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    \n",
    "    y_true = y_true.reshape(1, -1)[0]\n",
    "    y_pred = y_pred.reshape(1, -1)[0]\n",
    "    over_threshold = y_true >= 0.1\n",
    "    \n",
    "    return np.mean(np.abs(y_true[over_threshold] - y_pred[over_threshold]))\n",
    "\n",
    "def fscore(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    \n",
    "    y_true = y_true.reshape(1, -1)[0]\n",
    "    y_pred = y_pred.reshape(1, -1)[0]\n",
    "    remove_NAs = y_true >= 0\n",
    "    \n",
    "    y_true = np.where(y_true[remove_NAs] >= 0.1, 1, 0)\n",
    "    y_pred = np.where(y_pred[remove_NAs] >= 0.1, 1, 0)\n",
    "    \n",
    "    return (f1_score(y_true, y_pred))\n",
    "\n",
    "def maeOverFscore(y_true, y_pred):\n",
    "    return 1\n",
    "    return mae(y_true, y_pred) / (fscore(y_true, y_pred) + 1e-07)\n",
    "\n",
    "def score(y_val, pred):\n",
    "    f_value =  fscore(y_val, pred)\n",
    "    mae_value = maeOverFscore(y_val, pred)\n",
    "    print(f\"fscore        : {f_value}\")\n",
    "    print(f\"maeOverFscore : {mae_value}\")\n",
    "    \n",
    "    return (f_value, mae_value)\n",
    "\n",
    "def maeOverFscore_lgb(y_true, y_pred):\n",
    "    return (\"maeOverFscore\", mae(y_true, y_pred) / (fscore(y_true, y_pred) + 1e-07), False)\n",
    "\n",
    "def fscore_lgb(y_true, y_pred):\n",
    "    return (\"fscore\", fscore(y_true, y_pred), False)\n",
    "\n",
    "fscore_sklearn = make_scorer(fscore)\n",
    "maeOverFscore_sklearn = make_scorer(maeOverFscore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = os.getcwd()\n",
    "data_path = os.path.join(base, 'data')\n",
    "submit_path = os.path.join(base, 'submit')\n",
    "model_path = os.path.join(base, 'model')\n",
    "\n",
    "def load_data(name):\n",
    "    return np.load(os.path.join(data_path, f\"{name}.npy\"))\n",
    "\n",
    "def reshape(data):\n",
    "    return data.reshape(data.shape[0] * 40 * 40, data.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = reshape(load_data('dl_train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seperate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121561600, 14) (121561600, 1)\n"
     ]
    }
   ],
   "source": [
    "X = data[:, :-1]\n",
    "Y = data[:,  -1].reshape(data.shape[0], 1)\n",
    "data = range(data.shape[0])\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LGBMRegressor in module lightgbm.sklearn:\n",
      "\n",
      "class LGBMRegressor(LGBMModel, sklearn.base.RegressorMixin)\n",
      " |  LGBMRegressor(boosting_type='gbdt', num_leaves=31, max_depth=-1, learning_rate=0.1, n_estimators=100, subsample_for_bin=200000, objective=None, class_weight=None, min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, n_jobs=-1, silent=True, importance_type='split', **kwargs)\n",
      " |  \n",
      " |  LightGBM regressor.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LGBMRegressor\n",
      " |      LGBMModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, init_score=None, eval_set=None, eval_names=None, eval_sample_weight=None, eval_init_score=None, eval_metric=None, early_stopping_rounds=None, verbose=True, feature_name='auto', categorical_feature='auto', callbacks=None)\n",
      " |      Build a gradient boosting model from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          Input feature matrix.\n",
      " |      y : array-like of shape = [n_samples]\n",
      " |          The target values (class labels in classification, real numbers in regression).\n",
      " |      sample_weight : array-like of shape = [n_samples] or None, optional (default=None)\n",
      " |          Weights of training data.\n",
      " |      init_score : array-like of shape = [n_samples] or None, optional (default=None)\n",
      " |          Init score of training data.\n",
      " |      group : array-like or None, optional (default=None)\n",
      " |          Group data of training data.\n",
      " |      eval_set : list or None, optional (default=None)\n",
      " |          A list of (X, y) tuple pairs to use as validation sets.\n",
      " |      eval_names : list of strings or None, optional (default=None)\n",
      " |          Names of eval_set.\n",
      " |      eval_sample_weight : list of arrays or None, optional (default=None)\n",
      " |          Weights of eval data.\n",
      " |      eval_init_score : list of arrays or None, optional (default=None)\n",
      " |          Init score of eval data.\n",
      " |      eval_group : list of arrays or None, optional (default=None)\n",
      " |          Group data of eval data.\n",
      " |      eval_metric : string, list of strings, callable or None, optional (default=None)\n",
      " |          If string, it should be a built-in evaluation metric to use.\n",
      " |          If callable, it should be a custom evaluation metric, see note below for more details.\n",
      " |          In either case, the ``metric`` from the model parameters will be evaluated and used as well.\n",
      " |          Default: 'l2' for LGBMRegressor, 'logloss' for LGBMClassifier, 'ndcg' for LGBMRanker.\n",
      " |      early_stopping_rounds : int or None, optional (default=None)\n",
      " |          Activates early stopping. The model will train until the validation score stops improving.\n",
      " |          Validation score needs to improve at least every ``early_stopping_rounds`` round(s)\n",
      " |          to continue training.\n",
      " |          Requires at least one validation data and one metric.\n",
      " |          If there's more than one, will check all of them. But the training data is ignored anyway.\n",
      " |          To check only the first metric, set the ``first_metric_only`` parameter to ``True``\n",
      " |          in additional parameters ``**kwargs`` of the model constructor.\n",
      " |      verbose : bool or int, optional (default=True)\n",
      " |          Requires at least one evaluation data.\n",
      " |          If True, the eval metric on the eval set is printed at each boosting stage.\n",
      " |          If int, the eval metric on the eval set is printed at every ``verbose`` boosting stage.\n",
      " |          The last boosting stage or the boosting stage found by using ``early_stopping_rounds`` is also printed.\n",
      " |      \n",
      " |          .. rubric:: Example\n",
      " |      \n",
      " |          With ``verbose`` = 4 and at least one item in ``eval_set``,\n",
      " |          an evaluation metric is printed every 4 (instead of 1) boosting stages.\n",
      " |      \n",
      " |      feature_name : list of strings or 'auto', optional (default='auto')\n",
      " |          Feature names.\n",
      " |          If 'auto' and data is pandas DataFrame, data columns names are used.\n",
      " |      categorical_feature : list of strings or int, or 'auto', optional (default='auto')\n",
      " |          Categorical features.\n",
      " |          If list of int, interpreted as indices.\n",
      " |          If list of strings, interpreted as feature names (need to specify ``feature_name`` as well).\n",
      " |          If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.\n",
      " |          All values in categorical features should be less than int32 max value (2147483647).\n",
      " |          Large values could be memory consuming. Consider using consecutive integers starting from zero.\n",
      " |          All negative values in categorical features will be treated as missing values.\n",
      " |          The output cannot be monotonically constrained with respect to a categorical feature.\n",
      " |      callbacks : list of callback functions or None, optional (default=None)\n",
      " |          List of callback functions that are applied at each iteration.\n",
      " |          See Callbacks in Python API for more information.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |      \n",
      " |      Note\n",
      " |      ----\n",
      " |      Custom eval function expects a callable with following signatures:\n",
      " |      ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n",
      " |      ``func(y_true, y_pred, weight, group)``\n",
      " |      and returns (eval_name, eval_result, is_higher_better) or\n",
      " |      list of (eval_name, eval_result, is_higher_better):\n",
      " |      \n",
      " |          y_true : array-like of shape = [n_samples]\n",
      " |              The target values.\n",
      " |          y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      " |              The predicted values.\n",
      " |          weight : array-like of shape = [n_samples]\n",
      " |              The weight of samples.\n",
      " |          group : array-like\n",
      " |              Group/query data, used for ranking task.\n",
      " |          eval_name : string\n",
      " |              The name of evaluation function (without whitespaces).\n",
      " |          eval_result : float\n",
      " |              The eval result.\n",
      " |          is_higher_better : bool\n",
      " |              Is eval result higher better, e.g. AUC is ``is_higher_better``.\n",
      " |      \n",
      " |      For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
      " |      If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i].\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from LGBMModel:\n",
      " |  \n",
      " |  __init__(self, boosting_type='gbdt', num_leaves=31, max_depth=-1, learning_rate=0.1, n_estimators=100, subsample_for_bin=200000, objective=None, class_weight=None, min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, n_jobs=-1, silent=True, importance_type='split', **kwargs)\n",
      " |      Construct a gradient boosting model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      boosting_type : string, optional (default='gbdt')\n",
      " |          'gbdt', traditional Gradient Boosting Decision Tree.\n",
      " |          'dart', Dropouts meet Multiple Additive Regression Trees.\n",
      " |          'goss', Gradient-based One-Side Sampling.\n",
      " |          'rf', Random Forest.\n",
      " |      num_leaves : int, optional (default=31)\n",
      " |          Maximum tree leaves for base learners.\n",
      " |      max_depth : int, optional (default=-1)\n",
      " |          Maximum tree depth for base learners, <=0 means no limit.\n",
      " |      learning_rate : float, optional (default=0.1)\n",
      " |          Boosting learning rate.\n",
      " |          You can use ``callbacks`` parameter of ``fit`` method to shrink/adapt learning rate\n",
      " |          in training using ``reset_parameter`` callback.\n",
      " |          Note, that this will ignore the ``learning_rate`` argument in training.\n",
      " |      n_estimators : int, optional (default=100)\n",
      " |          Number of boosted trees to fit.\n",
      " |      subsample_for_bin : int, optional (default=200000)\n",
      " |          Number of samples for constructing bins.\n",
      " |      objective : string, callable or None, optional (default=None)\n",
      " |          Specify the learning task and the corresponding learning objective or\n",
      " |          a custom objective function to be used (see note below).\n",
      " |          Default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n",
      " |      class_weight : dict, 'balanced' or None, optional (default=None)\n",
      " |          Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |          Use this parameter only for multi-class classification task;\n",
      " |          for binary classification task you may use ``is_unbalance`` or ``scale_pos_weight`` parameters.\n",
      " |          Note, that the usage of all these parameters will result in poor estimates of the individual class probabilities.\n",
      " |          You may want to consider performing probability calibration\n",
      " |          (https://scikit-learn.org/stable/modules/calibration.html) of your model.\n",
      " |          The 'balanced' mode uses the values of y to automatically adjust weights\n",
      " |          inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |          If None, all classes are supposed to have weight one.\n",
      " |          Note, that these weights will be multiplied with ``sample_weight`` (passed through the ``fit`` method)\n",
      " |          if ``sample_weight`` is specified.\n",
      " |      min_split_gain : float, optional (default=0.)\n",
      " |          Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
      " |      min_child_weight : float, optional (default=1e-3)\n",
      " |          Minimum sum of instance weight (hessian) needed in a child (leaf).\n",
      " |      min_child_samples : int, optional (default=20)\n",
      " |          Minimum number of data needed in a child (leaf).\n",
      " |      subsample : float, optional (default=1.)\n",
      " |          Subsample ratio of the training instance.\n",
      " |      subsample_freq : int, optional (default=0)\n",
      " |          Frequence of subsample, <=0 means no enable.\n",
      " |      colsample_bytree : float, optional (default=1.)\n",
      " |          Subsample ratio of columns when constructing each tree.\n",
      " |      reg_alpha : float, optional (default=0.)\n",
      " |          L1 regularization term on weights.\n",
      " |      reg_lambda : float, optional (default=0.)\n",
      " |          L2 regularization term on weights.\n",
      " |      random_state : int or None, optional (default=None)\n",
      " |          Random number seed.\n",
      " |          If None, default seeds in C++ code will be used.\n",
      " |      n_jobs : int, optional (default=-1)\n",
      " |          Number of parallel threads.\n",
      " |      silent : bool, optional (default=True)\n",
      " |          Whether to print messages while running boosting.\n",
      " |      importance_type : string, optional (default='split')\n",
      " |          The type of feature importance to be filled into ``feature_importances_``.\n",
      " |          If 'split', result contains numbers of times the feature is used in a model.\n",
      " |          If 'gain', result contains total gains of splits which use the feature.\n",
      " |      **kwargs\n",
      " |          Other parameters for the model.\n",
      " |          Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n",
      " |      \n",
      " |          .. warning::\n",
      " |      \n",
      " |              \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n",
      " |      \n",
      " |      Attributes\n",
      " |      ----------\n",
      " |      n_features_ : int\n",
      " |          The number of features of fitted model.\n",
      " |      classes_ : array of shape = [n_classes]\n",
      " |          The class label array (only for classification problem).\n",
      " |      n_classes_ : int\n",
      " |          The number of classes (only for classification problem).\n",
      " |      best_score_ : dict or None\n",
      " |          The best score of fitted model.\n",
      " |      best_iteration_ : int or None\n",
      " |          The best iteration of fitted model if ``early_stopping_rounds`` has been specified.\n",
      " |      objective_ : string or callable\n",
      " |          The concrete objective used while fitting this model.\n",
      " |      booster_ : Booster\n",
      " |          The underlying Booster of this model.\n",
      " |      evals_result_ : dict or None\n",
      " |          The evaluation results if ``early_stopping_rounds`` has been specified.\n",
      " |      feature_importances_ : array of shape = [n_features]\n",
      " |          The feature importances (the higher, the more important the feature).\n",
      " |      \n",
      " |      Note\n",
      " |      ----\n",
      " |      A custom objective function can be provided for the ``objective`` parameter.\n",
      " |      In this case, it should have the signature\n",
      " |      ``objective(y_true, y_pred) -> grad, hess`` or\n",
      " |      ``objective(y_true, y_pred, group) -> grad, hess``:\n",
      " |      \n",
      " |          y_true : array-like of shape = [n_samples]\n",
      " |              The target values.\n",
      " |          y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      " |              The predicted values.\n",
      " |          group : array-like\n",
      " |              Group/query data, used for ranking task.\n",
      " |          grad : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      " |              The value of the first order derivative (gradient) for each sample point.\n",
      " |          hess : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      " |              The value of the second order derivative (Hessian) for each sample point.\n",
      " |      \n",
      " |      For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
      " |      If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]\n",
      " |      and you should group grad and hess in this way as well.\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, optional (default=True)\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  predict(self, X, raw_score=False, num_iteration=None, pred_leaf=False, pred_contrib=False, **kwargs)\n",
      " |      Return the predicted value for each sample.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          Input features matrix.\n",
      " |      raw_score : bool, optional (default=False)\n",
      " |          Whether to predict raw scores.\n",
      " |      num_iteration : int or None, optional (default=None)\n",
      " |          Limit number of iterations in the prediction.\n",
      " |          If None, if the best iteration exists, it is used; otherwise, all trees are used.\n",
      " |          If <= 0, all trees are used (no limits).\n",
      " |      pred_leaf : bool, optional (default=False)\n",
      " |          Whether to predict leaf index.\n",
      " |      pred_contrib : bool, optional (default=False)\n",
      " |          Whether to predict feature contributions.\n",
      " |      \n",
      " |          .. note::\n",
      " |      \n",
      " |              If you want to get more explanations for your model's predictions using SHAP values,\n",
      " |              like SHAP interaction values,\n",
      " |              you can install the shap package (https://github.com/slundberg/shap).\n",
      " |              Note that unlike the shap package, with ``pred_contrib`` we return a matrix with an extra\n",
      " |              column, where the last column is the expected value.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Other parameters for the prediction.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      predicted_result : array-like of shape = [n_samples] or shape = [n_samples, n_classes]\n",
      " |          The predicted values.\n",
      " |      X_leaves : array-like of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]\n",
      " |          If ``pred_leaf=True``, the predicted leaf of every tree for each sample.\n",
      " |      X_SHAP_values : array-like of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes]\n",
      " |          If ``pred_contrib=True``, the feature contributions for each sample.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params\n",
      " |          Parameter names with their new values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from LGBMModel:\n",
      " |  \n",
      " |  best_iteration_\n",
      " |      Get the best iteration of fitted model.\n",
      " |  \n",
      " |  best_score_\n",
      " |      Get the best score of fitted model.\n",
      " |  \n",
      " |  booster_\n",
      " |      Get the underlying lightgbm Booster of this model.\n",
      " |  \n",
      " |  evals_result_\n",
      " |      Get the evaluation results.\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Get feature importances.\n",
      " |      \n",
      " |      .. note::\n",
      " |      \n",
      " |          Feature importance in sklearn interface used to normalize to 1,\n",
      " |          it's deprecated after 2.0.4 and is the same as Booster.feature_importance() now.\n",
      " |          ``importance_type`` attribute is passed to the function\n",
      " |          to configure the type of importance values to be extracted.\n",
      " |  \n",
      " |  n_features_\n",
      " |      Get the number of features of fitted model.\n",
      " |  \n",
      " |  objective_\n",
      " |      Get the concrete objective used while fitting this model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a\n",
      " |          precomputed kernel matrix or a list of generic objects instead,\n",
      " |          shape = (n_samples, n_samples_fitted),\n",
      " |          where n_samples_fitted is the number of\n",
      " |          samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The R2 score used when calling ``score`` on a regressor will use\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with :func:`~sklearn.metrics.r2_score`. This will influence the\n",
      " |      ``score`` method of all the multioutput regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`). To specify the\n",
      " |      default value manually and avoid the warning, please either call\n",
      " |      :func:`~sklearn.metrics.r2_score` directly or make a custom scorer with\n",
      " |      :func:`~sklearn.metrics.make_scorer` (the built-in scorer ``'r2'`` uses\n",
      " |      ``multioutput='uniform_average'``).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(lgb.LGBMRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMRegressor(boosting_type='gbdt', num_leaves=31, max_depth=- 1, learning_rate=0.01, \\\n",
    "                        n_estimators=100, subsample_for_bin=200000, objective=None, class_weight=None, \\\n",
    "                        min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, \\\n",
    "                        subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, \\\n",
    "                        random_state=7, n_jobs=- 1, silent=True, importance_type='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:253: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  warnings.warn(\"Usage of np.ndarray subset (sliced data) is not recommended \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tmaeOverFscore's l2: 2.48526\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tmaeOverFscore's l2: 2.47236\n",
      "[3]\tmaeOverFscore's l2: 2.46006\n",
      "[4]\tmaeOverFscore's l2: 2.44751\n",
      "[5]\tmaeOverFscore's l2: 2.43565\n",
      "[6]\tmaeOverFscore's l2: 2.42431\n",
      "[7]\tmaeOverFscore's l2: 2.41347\n",
      "[8]\tmaeOverFscore's l2: 2.40251\n",
      "[9]\tmaeOverFscore's l2: 2.39159\n",
      "[10]\tmaeOverFscore's l2: 2.3818\n",
      "[11]\tmaeOverFscore's l2: 2.37148\n",
      "[12]\tmaeOverFscore's l2: 2.36184\n",
      "[13]\tmaeOverFscore's l2: 2.35224\n",
      "[14]\tmaeOverFscore's l2: 2.34296\n",
      "[15]\tmaeOverFscore's l2: 2.33398\n",
      "[16]\tmaeOverFscore's l2: 2.32542\n",
      "[17]\tmaeOverFscore's l2: 2.31694\n",
      "[18]\tmaeOverFscore's l2: 2.30903\n",
      "[19]\tmaeOverFscore's l2: 2.30178\n",
      "[20]\tmaeOverFscore's l2: 2.2943\n",
      "[21]\tmaeOverFscore's l2: 2.28696\n",
      "[22]\tmaeOverFscore's l2: 2.2804\n",
      "[23]\tmaeOverFscore's l2: 2.2738\n",
      "[24]\tmaeOverFscore's l2: 2.26215\n",
      "[25]\tmaeOverFscore's l2: 2.25607\n",
      "[26]\tmaeOverFscore's l2: 2.24519\n",
      "[27]\tmaeOverFscore's l2: 2.23674\n",
      "[28]\tmaeOverFscore's l2: 2.23116\n",
      "[29]\tmaeOverFscore's l2: 2.22547\n",
      "[30]\tmaeOverFscore's l2: 2.21486\n",
      "[31]\tmaeOverFscore's l2: 2.20739\n",
      "[32]\tmaeOverFscore's l2: 2.20236\n",
      "[33]\tmaeOverFscore's l2: 2.19223\n",
      "[34]\tmaeOverFscore's l2: 2.18551\n",
      "[35]\tmaeOverFscore's l2: 2.17897\n",
      "[36]\tmaeOverFscore's l2: 2.16848\n",
      "[37]\tmaeOverFscore's l2: 2.16231\n",
      "[38]\tmaeOverFscore's l2: 2.15344\n",
      "[39]\tmaeOverFscore's l2: 2.14761\n",
      "[40]\tmaeOverFscore's l2: 2.14216\n",
      "[41]\tmaeOverFscore's l2: 2.13308\n",
      "[42]\tmaeOverFscore's l2: 2.12782\n",
      "[43]\tmaeOverFscore's l2: 2.12481\n",
      "[44]\tmaeOverFscore's l2: 2.11618\n",
      "[45]\tmaeOverFscore's l2: 2.11129\n",
      "[46]\tmaeOverFscore's l2: 2.10846\n",
      "[47]\tmaeOverFscore's l2: 2.10587\n",
      "[48]\tmaeOverFscore's l2: 2.10149\n",
      "[49]\tmaeOverFscore's l2: 2.09363\n",
      "[50]\tmaeOverFscore's l2: 2.08956\n",
      "[51]\tmaeOverFscore's l2: 2.08746\n",
      "[52]\tmaeOverFscore's l2: 2.08031\n",
      "[53]\tmaeOverFscore's l2: 2.07658\n",
      "[54]\tmaeOverFscore's l2: 2.07443\n",
      "[55]\tmaeOverFscore's l2: 2.06753\n",
      "[56]\tmaeOverFscore's l2: 2.06552\n",
      "[57]\tmaeOverFscore's l2: 2.06326\n",
      "[58]\tmaeOverFscore's l2: 2.05607\n",
      "[59]\tmaeOverFscore's l2: 2.05412\n",
      "[60]\tmaeOverFscore's l2: 2.04993\n",
      "[61]\tmaeOverFscore's l2: 2.04679\n",
      "[62]\tmaeOverFscore's l2: 2.04199\n",
      "[63]\tmaeOverFscore's l2: 2.03623\n",
      "[64]\tmaeOverFscore's l2: 2.03168\n",
      "[65]\tmaeOverFscore's l2: 2.02845\n",
      "[66]\tmaeOverFscore's l2: 2.02307\n",
      "[67]\tmaeOverFscore's l2: 2.02165\n",
      "[68]\tmaeOverFscore's l2: 2.01856\n",
      "[69]\tmaeOverFscore's l2: 2.01309\n",
      "[70]\tmaeOverFscore's l2: 2.01024\n",
      "[71]\tmaeOverFscore's l2: 2.00559\n",
      "[72]\tmaeOverFscore's l2: 2.00277\n",
      "[73]\tmaeOverFscore's l2: 1.99578\n",
      "[74]\tmaeOverFscore's l2: 1.99431\n",
      "[75]\tmaeOverFscore's l2: 1.99194\n",
      "[76]\tmaeOverFscore's l2: 1.99083\n",
      "[77]\tmaeOverFscore's l2: 1.98477\n",
      "[78]\tmaeOverFscore's l2: 1.98381\n",
      "[79]\tmaeOverFscore's l2: 1.97902\n",
      "[80]\tmaeOverFscore's l2: 1.97797\n",
      "[81]\tmaeOverFscore's l2: 1.97766\n",
      "[82]\tmaeOverFscore's l2: 1.97363\n",
      "[83]\tmaeOverFscore's l2: 1.97363\n",
      "[84]\tmaeOverFscore's l2: 1.97016\n",
      "[85]\tmaeOverFscore's l2: 1.96657\n",
      "[86]\tmaeOverFscore's l2: 1.96317\n",
      "[87]\tmaeOverFscore's l2: 1.95871\n",
      "[88]\tmaeOverFscore's l2: 1.95245\n",
      "[89]\tmaeOverFscore's l2: 1.9464\n",
      "[90]\tmaeOverFscore's l2: 1.94335\n",
      "[91]\tmaeOverFscore's l2: 1.94045\n",
      "[92]\tmaeOverFscore's l2: 1.94007\n",
      "[93]\tmaeOverFscore's l2: 1.93721\n",
      "[94]\tmaeOverFscore's l2: 1.9358\n",
      "[95]\tmaeOverFscore's l2: 1.93444\n",
      "[96]\tmaeOverFscore's l2: 1.93144\n",
      "[97]\tmaeOverFscore's l2: 1.92597\n",
      "[98]\tmaeOverFscore's l2: 1.92074\n",
      "[99]\tmaeOverFscore's l2: 1.91711\n",
      "[100]\tmaeOverFscore's l2: 1.91184\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tmaeOverFscore's l2: 1.91184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.01, max_depth=-1,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "              random_state=7, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X[:1000000, :], Y[:1000000, 0], eval_set=[(X[-1000000:, :], Y[-1000000:, 0])], \\\n",
    "        eval_metric=[maeOverFscore_sklearn, fscore_sklearn], eval_names =[\"maeOverFscore\", \"fscore\"],\\\n",
    "        early_stopping_rounds=50, \\\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    boosting_type:'gbdt', num_leaves:31, max_depth:- 1, learning_rate:0.01, \\\n",
    "                        n_estimators:10, subsample_for_bin:200000, objective=None, class_weight=None, \\\n",
    "                        min_split_gain:0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, \\\n",
    "                        subsample_freq:0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, \\\n",
    "                        random_state=7, n_jobs=- 1, silent=True, importance_type='split'\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e804b095f4af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m clf_train = lgb.train(params, train_set, num_boost_round=100, valid_sets=None, valid_names=None, \\\n\u001b[0m\u001b[1;32m      2\u001b[0m                \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                keep_training_booster=False, callbacks=None)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "clf_train = lgb.train(params, train_set, num_boost_round=1000, valid_sets=None, valid_names=\"val\", \\\n",
    "               fobj=None, feval=None, init_model=None, feature_name='auto', categorical_feature='auto', \\\n",
    "               early_stopping_rounds=50, evals_result=None, verbose_eval=10, learning_rates=None, \\\n",
    "               keep_training_booster=False, callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "          'objective': 'binary',\n",
    "          'nthread': 3, # Updated from nthread\n",
    "          'num_leaves': 64,\n",
    "          'learning_rate': 0.01,\n",
    "          'max_bin': 512,\n",
    "          'subsample_for_bin': 200,\n",
    "          'subsample': 1,\n",
    "          'subsample_freq': 1,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'reg_alpha': 5,\n",
    "          'reg_lambda': 10,\n",
    "          'min_split_gain': 0.5,\n",
    "          'min_child_weight': 1,\n",
    "          'min_child_samples': 5,\n",
    "          'scale_pos_weight': 1,\n",
    "          'num_class' : 1,\n",
    "          'metric' : 'binary_error'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'learning_rate': 0.01, \n",
    "          'max_depth': 16, \n",
    "          'boosting': 'gbdt', \n",
    "          'objective': 'regression', \n",
    "          'metric': 'mae', \n",
    "          'is_training_metric': True, \n",
    "          'num_leaves': 144, \n",
    "          'feature_fraction': 0.9, \n",
    "          'bagging_fraction': 0.7, \n",
    "          'bagging_freq': 5, \n",
    "          'seed':2018}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-b2fb6b2e052d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m            \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmaeOverFscore_lgb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m            \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m            keep_training_booster=False, callbacks=None)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbest_iterations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    245\u001b[0m                                     \u001b[0mbegin_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_iteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                                     \u001b[0mend_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_iteration\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                                     evaluation_result_list=None))\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/callback.py\u001b[0m in \u001b[0;36m_callback\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mnew_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_iteration\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0mnew_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnew_param\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mnew_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_param\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "clf = lgb.train(params, train, num_boost_round=100, valid_sets=val, valid_names=\"val\", \\\n",
    "           fobj=None, feval=[maeOverFscore_lgb], init_model=None, feature_name='auto', categorical_feature='auto', \\\n",
    "           early_stopping_rounds=50, evals_result=results, verbose_eval=10, learning_rates=0.01, \\\n",
    "           keep_training_booster=False, callbacks=None)\n",
    "\n",
    "best_iterations.append(clf.best_iteration_)\n",
    "best_scores.append(clf.best_score_.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lightgbm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-1f63cd6de742>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     clf = lightgbm.train(params, train, num_boost_round=100, valid_sets=val, valid_names=\"val\", \\\n\u001b[0m\u001b[1;32m     13\u001b[0m                \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmaeOverFscore_lgb\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mfscore_lgb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lightgbm' is not defined"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=4, random_state=7, shuffle=False)\n",
    "scores = list()\n",
    "best_iterations = list()\n",
    "best_scores = list()\n",
    "results = dict()\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(kfold.split(data)):\n",
    "    train = lgb.Dataset(X[train_idx, :],  Y[train_idx, 0])\n",
    "    val = lgb.Dataset(X[val_idx, :],  Y[val_idx, 0])\n",
    "\n",
    "    \n",
    "    clf = lgb.train(params, train, num_boost_round=100, valid_sets=val, valid_names=\"val\", \\\n",
    "               fobj=None, feval=[maeOverFscore_lgb. fscore_lgb], init_model=None, feature_name='auto', categorical_feature='auto', \\\n",
    "               early_stopping_rounds=50, evals_result=results, verbose_eval=10, learning_rates=0.01, \\\n",
    "               keep_training_booster=False, callbacks=None)\n",
    "    \n",
    "    best_iterations.append(clf.best_iteration_)\n",
    "    best_scores.append(clf.best_score_.values())\n",
    "#     clf.booster_.save_model('clf.txt')\n",
    "    \n",
    "    scores.append(score(clf.predict(X[val_idx, :]), Y[val_idx, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = lgb.Dataset(X, Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x7f7084578390>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=4, random_state=7, shuffle=False)\n",
    "scores = list()\n",
    "best_iterations = list()\n",
    "best_scores = list()\n",
    "\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(kfold.split(data)):\n",
    "    clf = lgb.LGBMRegressor(boosting_type='gbdt', num_leaves=31, max_depth=- 1, learning_rate=0.01, \\\n",
    "                            n_estimators=10000, subsample_for_bin=200000, objective=None, class_weight=None, \\\n",
    "                            min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, \\\n",
    "                            subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, \\\n",
    "                            random_state=7, n_jobs=- 1, silent=True, importance_type='split')\n",
    "    \n",
    "\n",
    "    clf.fit(X[train_idx, :], Y[train_idx, 0], eval_set=[(X[val_idx, :], Y[val_idx, 0])], \\\n",
    "            eval_metric=[\"MAE\", \"MSE\"], \\\n",
    "            early_stopping_rounds=50, \\\n",
    "            verbose=True)\n",
    "    \n",
    "    best_iterations.append(clf.best_iteration_)\n",
    "    best_scores.append(clf.best_score_.values())\n",
    "#     clf.booster_.save_model('clf.txt')\n",
    "    \n",
    "    scores.append(score(clf.predict(X[val_idx, :]), Y[val_idx, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "lgb.plot_importance(clf, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMRegressor(boosting_type='gbdt', num_leaves=31, max_depth=- 1, learning_rate=0.01, \\\n",
    "                        n_estimators=800, subsample_for_bin=200000, objective=None, class_weight=None, \\\n",
    "                        min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, \\\n",
    "                        subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, \\\n",
    "                        random_state=7, n_jobs=- 1, silent=True, importance_type='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.01, max_depth=-1,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=800, n_jobs=-1, num_leaves=31, objective=None,\n",
       "              random_state=7, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, Y, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efca8701590>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "lgb.plot_importance(clf, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(clf, name, preprocess=None):\n",
    "    x_test = reshape(load_data('test'))\n",
    "    \n",
    "    pred = clf.predict(x_test)\n",
    "\n",
    "    submission = pd.read_csv(os.path.join(data_path, 'sample_submission.csv'))\n",
    "    submission.iloc[:, 1:] = pred.reshape(-1, 1600)\n",
    "\n",
    "    submission.to_csv(os.path.join(submit_path, f'{name}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(clf, 'lightbgm_all_31_800')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://dacon.io/competitions/official/235591/mysubmission/\n",
    "- D:\\인공지능_공모전\\github\\submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
